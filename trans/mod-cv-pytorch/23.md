

# 第 1 章-人工神经网络基础

1.  神经网络中的各层是什么？
    输入、隐藏和输出层
2.  前馈传播的输出是什么？
    帮助计算损失值的预测
3.  连续因变量的损失函数与二元因变量以及分类因变量的损失函数有何不同？MSE 是连续因变量的常用损失函数，二元因变量的常用交叉熵。分类交叉熵用于分类因变量。
4.  什么是随机梯度下降？
    这是一个减少损失的过程，通过向梯度递减的方向调整权重
5.  反向传播练习做什么？它使用链式法则计算所有权重相对于损失的梯度
6.  在反向传播期间，跨层的所有权重的权重更新是如何发生的？使用公式 dW = W–alpha *(dW/dL)来实现
7.  在训练神经网络的每个时期内，神经网络的所有功能是什么？
    对于一个时期中的每一批，执行正向推进- >、反向推进- >、更新权重- >对下一批重复，直到所有时期结束
8.  为什么在 GPU 上训练网络比在 CPU 上训练更快？在 GPU 硬件上可以并行执行更多矩阵运算

9.  学习率如何影响神经网络的训练？过高的学习率会使权重爆炸，过低的学习率根本不会改变权重
10.  学习率参数的典型值是多少？1e-2 至 1e-5

# 第 2 章- PyTorch 基础知识

1.  训练时为什么要把整数输入转换成浮点值？
    `nn.Linear`(以及几乎所有的火炬层)只接受浮动作为输入
2.  重塑张量物体的各种方法有哪些？
    重塑、查看
3.  为什么张量对象比 NumPy 数组的计算速度更快？在 GPU 上并行运行的能力仅在张量对象上可用
4.  神经网络类中的 init 神奇函数是由什么构成的？
    调用`super().__init__()`并指定神经网络的层数
5.  为什么我们在执行反向传播之前执行零梯度？
    确保冲洗掉之前计算的梯度
6.  数据集类由哪些神奇的函数构成？
    `__len__`和`__getitem__`
7.  我们如何对新的数据点做出预测？
    通过在张量上调用模型，就好像它是一个函数-模型(x)
8.  我们如何获取神经网络的中间层值？
    通过创建自定义方法
9.  `Sequential`方法如何帮助简化神经网络架构的定义？
    我们可以通过连接一系列层来避免创建`__init__`和`forward`方法

# 第 3 章-使用 PyTorch 构建深度神经网络

1.  如果输入值未在输入数据集中进行缩放，会出现什么问题？
    将权重调整到最佳值需要更长时间，因为输入值在未缩放时变化很大
2.  在训练神经网络时，如果背景具有白色像素颜色，而内容具有黑色像素颜色，会出现什么问题？神经网络必须学会忽略大多数不太有用的白色内容
3.  批量大小对模型的训练时间、给定数量的时期的准确性有什么影响？
    批量越大，收敛所需的时间越长，达到高精度所需的迭代次数也越多
4.  训练结束时，输入值范围对权重分布有什么影响？
    如果输入值没有缩放到某个范围，某些权重会有助于过度拟合
5.  批处理规范化如何帮助提高准确性？
    正如我们缩放输入以更好地收敛人工神经网络是多么重要一样，批量标准化缩放激活以更好地收敛其下一层
6.  我们如何知道一个模型是否过度适合训练数据？当验证损失是常数或随着更多的时期而不断增加，而训练损失随着时期的增加而不断减少时
7.  正则化如何帮助避免过度拟合？正则化技术有助于模型在受限环境中训练，从而迫使人工神经网络以更少偏差的方式调整其权重
8.  L1 正则化和 L2 正则化有何不同？
    L1 =权重绝对值之和，L2 =除典型损失之外的损失值加上权重平方之和
9.  辍学如何有助于减少过度拟合？通过减少人工神经网络中的一些连接，我们迫使网络从更少的数据中学习。这迫使模型一般化。

# 第 4 章-介绍卷积神经网络

1.  为什么在使用传统神经网络时，对翻译图像的预测很低？所有图像都位于原始数据集中的中心，因此人工神经网络只学习位于中心的图像的任务。
2.  卷积是怎么做的？
    卷积是两个矩阵之间的乘法。
3.  如何确定过滤器中的最佳重量值？
    通过反向传播。
4.  卷积和汇集的结合如何帮助解决图像转换的问题？
    虽然卷积给出了重要的图像特征，但是汇集提取了图像片中最显著的特征。这使得池化在邻近区域上是一个健壮的操作，即，即使某些东西被平移了几个像素，池化仍将返回预期的输出。
5.  更接近输入层的层中的过滤器学习什么？像边缘这样的低级特征。
6.  池化有助于构建模型的功能是什么？
    它通过减少特征图大小来减少输入大小，并使模型平移不变。
7.  为什么我们不能获取输入图像，就像我们在 FashionMNIST 数据集上所做的那样展平，并为真实世界的图像训练一个模型？如果图像尺寸非常大，那么连接两个层的参数数量将会以百万计。
8.  数据增强如何帮助改善图像翻译？
    数据增强创建了被平移了几个像素的图像副本。因此，即使图像中的对象偏离中心，模型也被迫学习正确的类。
9.  在什么场景下我们利用`collate_fn`进行数据加载？
    当我们需要执行批处理级别的转换时，这在`__getitem__`中很难/很慢地执行。
10.  改变训练数据点的数量对验证数据集的分类准确性有什么影响？
    一般来说，数据集越大，模型精度就越好。

# 第五章-图像分类的迁移学习

1.  VGG 和 ResNet 预培训架构的培训内容是什么？
    Imagenet 数据集中的图像。
2.  为什么 VGG11 的精度不如 VGG16？与 VGG16 相比，VGG11 的层数较少。
3.  VGG11 中的数字 11 代表什么？
    11 层。
4.  残余网络中的残余是什么？
    除了层的变换，层还返回输入。
5.  残余网络的优势是什么？它有助于避免渐变消失，也有助于增加模型深度。
6.  有哪些各种流行的预训模型？VGG，雷斯网，盗梦空间，AlexNet。
7.  在迁移学习过程中，为什么要使用与预训练模型的训练中使用的相同的均值和标准差来标准化图像？
    模型被训练成使得它们期望输入图像用特定的平均值和标准偏差来归一化。
8.  为什么我们要冻结模型中的某些参数？
    我们冻结，以便参数在反向传播期间不会更新。他们没有更新，因为他们已经训练有素。
9.  我们如何知道预训练模型中存在的各种模块？
    `print(model)`
10.  我们如何训练一个能同时预测分类值和数值的模型？
    通过使用多个预测头，并使用每个预测头的单独损失进行训练。
11.  如果我们执行与我们在年龄和性别估计一节中所写的相同的代码，为什么年龄和性别预测代码可能不总是对您感兴趣的图像起作用？
    与训练数据不具有相似分布的图像可能会产生意想不到的结果。
12.  我们如何进一步提高我们在面部关键点预测部分中编写的面部关键点识别模型的准确性？我们可以在训练过程中添加颜色和几何增强。

# 第 6 章-图像分类的实际应用

1.  类激活图是如何获得的？
    参考生成凸轮一节中提供的 8 个步骤

2.  批量规范化和数据扩充在训练模型时有什么帮助？它们有助于减少过度拟合

3.  CNN 模型过度拟合的常见原因是什么？
    无批量标准化、数据扩充、丢失

4.  CNN 模型在数据科学家端处理训练和验证数据，但在现实世界中不处理的各种场景有哪些？真实世界的数据可能与用于训练和验证模型的数据具有不同的分布。此外，模型可能会过度拟合训练数据

5.  我们利用 OpenCV 包的各种场景是什么？
    在受限环境中工作时，以及推断速度更重要时

# 第 7 章-物体检测的基础

1.  区域提议技术如何生成提议？它识别颜色、纹理、大小和形状相似的区域。
2.  如果一个图像中有多个对象，如何计算 IoU？
    IoU 是使用交集/并集度量为每个对象计算的
3.  为什么 R-CNN 生成预测需要很长时间？因为有多少提议，我们就创建多少正向传播
4.  为什么快速 R-CNN 比 R-CNN 快？对于所有提案，从 VGG 主干提取特征图是常见的。与快速 RCNN 相比，这减少了几乎 90%的计算

5.  投资回报池是如何工作的？
    所有的`selectivesearch`作物都经过自适应池内核，因此最终输出的大小相同
6.  在预测边界框校正时，获取要素地图后没有多个图层会有什么影响？你可能没有注意到模型没有学会准确预测边界框
7.  为什么在计算总体损失时，我们必须给回归损失分配较高的权重？分类损失是交叉熵，其通常为 log(n)量级，导致输出可能具有高范围。然而，边界框回归损失介于 0 和 1 之间。因此，回归损失必须按比例增加。
8.  非最大抑制是如何工作的？通过组合相同类别且具有高 iou 的盒子，我们消除了冗余的包围盒预测。

# 第 8 章-高级对象检测

1.  为什么快速 R-CNN 比快速 R-CNN 更快？
    使用`selectivesearch`技术，我们不需要每次都输入大量不必要的提议。相反，更快的 R-CNN 使用区域提议网络自动找到他们。
2.  与更快的 R-CNN 相比，YOLO 和 SSD 的速度如何？我们不需要依赖新的提案网络。该网络一次就能直接找到这些建议。
3.  是什么让 YOLO 和 SSD 单次检测算法？网络一次性预测所有的提议和预测
4.  客观分和类分有什么区别？对象性标识一个对象是否存在。但是类分数预测了对象非零的锚盒的类

# 第九章-图像分割

1.  向上扩展对 U-Net 架构有何帮助？
    放大有助于增加特征地图的大小，以便最终输出与输入大小相同。
2.  U-Net 中为什么需要全卷积网络？
    因为输出也是图像，并且很难使用线性层来预测图像成形张量。
3.  在 Mask R-CNN 中，RoI Align 如何改进 RoI pooling？
    RoI Align 采用预测建议的偏移来精确对齐特征图。
4.  U-Net 和 Mask R-CNN 在分割方面的主要区别是什么？U-Net 是完全卷积的，具有单个端到端网络，而 Mask R-CNN 使用诸如 Backbone、RPN 等迷你网络来完成不同的任务。Mask R-CNN 能够识别和分离同类型的几个对象，而 U-Net 只能识别(但不能分离成单个实例)。
5.  什么是实例分段？如果在同一个图像中有同一个类的不同对象，那么每个这样的对象被称为一个实例。应用图像分割在像素级别上分别预测所有实例被称为实例分割。

# 第 11 章-自编码器和图像处理

1.  autoencoder 中的编码器是什么？
    将图像转换成矢量表示的较小的神经网络。
2.  autoencoder 针对什么损失函数进行优化？
    像素级均方误差，直接比较预测与输入。
3.  自编码器如何帮助分组相似的图像？
    相似的图像会返回相似的编码，更容易聚类。
4.  卷积自编码器什么时候有用？
    当输入是图像时。

5.  如果我们从普通/卷积自编码器获得的嵌入向量空间中随机采样，为什么会得到不直观的图像？
    编码中的数值范围不受限制，因此正确的输出高度依赖于正确的数值范围。一般来说，随机抽样假设平均值为 0，标准差为 1。
6.  变分自编码器优化的损失函数是什么？
    像素级 MSE 和 KL-来自编码器的平均值和标准偏差分布的散度。
7.  变分自编码器如何克服普通/卷积自编码器生成新图像的限制？
    通过将预测编码限制为正态分布，所有编码都落在均值-0 和标准偏差 1 的区域内，这很容易采样。
8.  在对抗性攻击中，为什么我们修改输入图像像素而不是权重值？在对抗性攻击中，我们无法控制神经网络。
9.  在神经类型转移中，我们优化的损失是什么？
    生成图像与原始图像的感知(VGG)损失，以及来自生成图像和风格图像的格拉姆矩阵的风格损失。
10.  为什么我们在计算样式和内容损失时考虑不同图层的激活而不考虑原始图像？
    使用更多中间层可确保生成的图像保留图像的更精细细节。此外，使用更多损耗会使梯度上升更加稳定。
11.  为什么我们在计算风格损失时考虑的是克矩阵损失而不是图像之间的差异？Gram matrix 给出了图像风格的指示，即纹理、形状和颜色是如何排列的，并且将忽略实际内容。这就是为什么它更方便风格的损失。
12.  为什么我们在建立模型的时候会扭曲图像，从而产生深度假像？扭曲图像有助于规则化。此外，它有助于生成所需数量的图像。

# 第 12 章-使用 GANs 生成图像

1.  如果生成器和鉴别器模型的学习率很高会怎么样？根据经验，观察到模型稳定性较低。
2.  在生成器和鉴别器训练有素的场景中，给定图像是真实的概率是多少？
    0.5。
3.  为什么我们在生成图像时使用 convtranspose2d？我们不能使用线性图层来放大/生成图像。
4.  为什么我们在条件 GANs 中嵌入的大小比类的数量大？使用更多的参数给予模型更多的自由度来学习每一类的重要特征。
5.  我们如何生成有胡子的男人的图像？
    用有条件的 GAN。就像我们有男性和女性的形象，我们可以有胡子的男性和其他类似的类，而训练模型。
6.  为什么我们在发生器的最后一层激活 Tanh，而不是 ReLU 或 Sigmoid？
    归一化图像的像素范围是[-1，1]，因此我们使用 Tanh
7.  为什么我们得到了真实的图像，即使我们没有对生成的数据去归一化？
    即使像素值不在[0，255]之间，相对值也足以让`make_grid`实用程序去归一化输入
8.  如果我们在训练 GAN 之前不裁剪对应于图像的面部，会发生什么？如果有太多的背景，GAN 会得到关于什么是脸什么不是脸的错误信号，因此它可能会专注于生成更真实的背景
9.  为什么训练发生器更新时鉴频器的权重不更新(因为`generator_train_step`函数涉及鉴频器网络)？
    这是一个循序渐进的过程。当更新生成器时，我们假设鉴别器能够做到最好。
10.  为什么我们在训练鉴别器时得到真实和虚假图像的损失，而在训练生成器时只得到虚假图像的损失？因为无论发生器创造了什么，都只是虚假的图像。

# 第 13 章-处理图像的高级 GANs

1.  为什么我们需要 Pix2Pix GAN，而像 U-Net 这样的监督学习算法可以从轮廓中生成图像？
    U-net 在训练时只使用像素级损失。我们需要 pix2pix，因为 U-net 生成图像时不会损失真实感。
2.  为什么我们需要在 CycleGAN 中针对 3 种不同的损失函数进行优化？
    在 CycleGAN 的第 7 点中提供了答案。
3.  进步中的技巧如何帮助建立风格？ProgressiveGAN 帮助网络一次学习几个上采样层，以便当图像必须增加尺寸时，负责生成当前尺寸图像的网络是最佳的。
4.  我们如何识别对应于给定自定义图像的潜在向量？
    通过调整随机产生的噪声，使得产生的图像和感兴趣的图像之间的 MSE 损失尽可能最小。

# 第 14 章-用最少的数据点进行训练

1.  预训练的词向量是如何获得的？
    来自现有数据库，如 GLOVE 或 word2vec
2.  零拍学习中我们如何从一个图像特征嵌入映射到单词嵌入？
    通过创建一个合适的神经网络，该网络返回一个与单词嵌入形状相同的向量，并用 mse-loss 进行训练(将预测与实际单词嵌入进行比较)
3.  暹罗网为什么这么叫？因为我们总是产生两个输出并相互比较，以确保一致性。暹罗代表双胞胎。
4.  暹罗网是怎么得出两幅图像的相似度的？
    损失函数迫使网络预测，如果图像相似，输出具有较小的距离。

# 第 15 章-结合计算机视觉和自然语言处理技术

1.  为什么 CNN 和 RNN 在图像字幕中结合在一起？CNN 需要捕捉图像特征，而 RNN 需要创建语言输出。
2.  为什么图像字幕中提供了开始和结束标记，而手写转录中没有？CTC 丢失不需要这种令牌，而且，在 OCR 中，我们一次生成所有时间步的令牌。
3.  为什么在手写转录中利用 CTC 丢失功能？我们无法描绘图像中的时间步长。CTC 负责将关键图像特征与时间步长对齐。
4.  转换器如何帮助物体检测？通过将锚盒视为转换器解码器的嵌入输入，DETR 学习动态锚盒，从而帮助对象检测。

# 第十六章-结合计算机视觉和强化学习

1.  给定状态的值是如何计算的？通过计算该状态下的预期回报
2.  Q 表是如何填充的？
    通过计算所有状态的期望报酬
3.  为什么我们在国家行动价值计算中要有一个贴现因子？由于不确定性，我们不确定未来会如何发展。因此，我们通过贴现的方式来降低未来奖励的权重
4.  勘探开发战略的必要性是什么？只有开发会使模型停滞不前并变得可预测，因此模型应该能够探索并发现看不见的步骤，这些步骤甚至比模型已经知道的更有价值。

5.  深度 Q 学习的需求是什么？我们让神经网络学习可能的奖励系统，而不需要昂贵的算法，这些算法可能需要太多时间或要求整个环境的可见性。
6.  如何使用深度 Q 学习计算给定状态动作组合的值？它只是神经网络的输出。输入是状态，网络为给定状态下的每一个行为预测一个期望的回报。
7.  在卡拉环境下可能会有哪些动作？
    加速-[-1，0，1](刹车，不加速，加速)
    转向-[-1，0，1](左，不转向，右)