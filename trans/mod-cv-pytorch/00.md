# 零、前言

人工智能 ( **AI** )就在这里，已经成为一股强大的力量，正在推动一些日常使用的现代应用。就像火、轮子、石油、电和电子的发现/发明一样，人工智能正在以我们只能幻想的方式重塑我们的世界。人工智能在历史上一直是一个利基计算机科学学科，由少数实验室提供。但由于优秀理论的爆炸、计算能力的提高和数据的可用性，该领域自 2000 年代以来开始呈指数增长，并且没有任何迹象表明会很快放缓。
人工智能一次又一次地证明，只要有正确的算法和足够多的数据，它可以在有限的人工干预下自行学习任务，并产生与人类判断相媲美的结果，有时甚至超过人类判断。无论你是一个正在学习诀窍的菜鸟，还是一个驱动大型组织的老手，都有充分的理由了解人工智能是如何工作的。神经网络是人工智能算法中最灵活的一类，已经适应了包括结构化数据、文本和视觉领域在内的广泛应用。

这本书从神经网络的基础开始，涵盖了计算机视觉的 50 多个应用。首先，您将使用 NumPy、PyTorch 从头开始构建一个**神经网络** ( **NN** )，然后学习调整 NN 的超参数的最佳实践。随着我们的进展，你将学习 CNN，重点是图像分类的迁移学习。您还将了解构建神经网络模型时需要注意的实际问题。

接下来，您将了解多目标检测、分割，并使用 R-CNN 系列、SSD、YOLO、U-Net、Mask-RCNN 架构实现它们。然后，您将学习使用 Detectron2 框架来简化构建用于目标检测和人体姿态估计的神经网络的过程。最后，您将实现三维目标检测。

随后，您将学习自编码器和 GANs，重点是图像处理和生成。在这里，您将实现 VAE，DCGAN，CGAN，Pix2Pix，CycleGan，StyleGAN2，SRGAN，Style-Transfer 来处理各种任务的图像。

然后，您将学习在使用变形器执行 OCR、图像字幕、目标检测时结合 NLP 和 CV 技术。接下来，您将学习结合 RL 和 CV 技术来实现一个自动驾驶汽车代理。最后，您将完成将一个神经网络模型移植到产品中，并使用 OpenCV 库学习传统的 CV 技术。

# 这本书是给谁的

这本书是为 PyTorch 新手和中级机器学习从业者编写的，他们希望通过使用深度学习和 PyTorch 精通 CV 技术。那些刚刚开始使用 NNs 的人也会发现这本书很有用。Python 编程语言和机器学习的基础知识是你开始阅读这本书所需要的。

# 这本书涵盖的内容

[第 1 章](4c6e8ac2-af49-4255-bb7f-e04ed7333f11.xhtml)、*人工神经网络基础*，给你一个神经网络如何工作的完整细节。您将从学习与神经网络相关的关键术语开始。接下来，您将了解构建模块的工作细节，并在玩具数据集上从头开始构建神经网络。到本章结束时，你将对神经网络的工作方式有信心。

[第 2 章](f1d61b2c-dbb8-43ac-ac4e-75941daecc4c.xhtml)， *PyTorch 基础*，向您介绍如何使用 PyTorch。在了解使用 PyTorch 构建神经网络模型的不同方法之前，您将了解创建和操作张量对象的方法。您仍将使用玩具数据集，以便理解使用 PyTorch 的细节。

[第 3 章](067f7e89-9e76-4179-879d-c125f8968d25.xhtml)，*用 PyTorch 构建深度神经网络*，结合了前面章节已经涉及的所有内容，了解各种神经网络超参数对模型精度的影响。在本章结束时，你将对在真实数据集上使用神经网络充满信心。

[第 4 章](c184fff6-28cc-4e13-830b-3b2a21736f75.xhtml)，*介绍卷积神经网络*，详细介绍使用普通神经网络的挑战，您将了解卷积神经网络克服传统神经网络各种局限性的原因。您将深入了解 CNN 的工作细节，并了解其中的各种组件。接下来，您将学习处理图像的最佳实践。在这一章中，你将开始处理真实世界的图像，并学习 CNN 如何帮助图像分类的复杂性。

[第五章](03f73691-e878-4719-8fff-96d2f46e410b.xhtml)、*图像分类的迁移学习*，让你接触到解决现实世界中的图像分类问题。您将了解多迁移学习架构，并了解它如何帮助显著提高图像分类的准确性。接下来，您将利用迁移学习来实现面部关键点检测和年龄、性别估计的用例。

[第 6 章](79080932-66ab-483e-95b6-c1ab858742ab.xhtml)、*影像分类的实际方面*，提供了在构建和部署影像分类模型时需要注意的实际方面的见解。您将实际看到在真实世界数据上利用数据扩充和批量规范化的优势。此外，您将了解到类激活图如何帮助解释 CNN 模型预测某种结果的原因。本章结束时，您可以自信地解决大多数影像分类问题，并在您的自定义数据集上利用前 3 章中讨论的模型。

[第 7 章](1d1dcdce-2034-4501-ab20-6196eea7f75c.xhtml)，*，*目标检测的基础知识为目标检测打下基础，在这里你将学习用于建立目标检测模型的各种技术。接下来，您将通过一个用例了解基于区域提议的目标检测技术，在这个用例中，您将实现一个模型来定位图像中的卡车和公共汽车。

[第 8 章](028d9c3a-56be-4695-9c2e-250d8329ca84.xhtml)、*高级目标检测*，向您展示基于区域提议的架构的局限性。然后，您将了解更高级的架构的工作细节，这些架构解决了基于区域提议的架构的问题。您将在同一个数据集上实现所有架构(卡车与公共汽车检测)，这样您就可以对比每个架构的工作原理。

[第 9 章](40b56752-6dda-4449-8535-6bfcf5e534d8.xhtml)、*图像分割*，建立在前面章节的学习基础上，将帮助您建立模型，精确定位图像中各类物体以及物体实例的位置。您将在道路图像和普通家庭图像上实现用例。在本章结束时，你将自信地处理任何图像分类、目标检测/分割问题，并通过使用 PyTorch 建立模型来解决它。

[第 10 章](9b3e4a1d-dfbb-4580-920c-5ff1238021b2.xhtml)、*目标检测和分割的应用*，总结了前面所有章节的学习内容，您将在几行代码中实现目标检测、分割，实现模型以执行人群计数和图像着色。最后，您还将了解如何在真实数据集上进行 3D 目标检测。

[第十一章](81f4bbcc-3744-4529-833d-79e878814be0.xhtml)，*自编码器和图像处理*，，为修改图像奠定基础。首先，您将了解各种有助于压缩图像和生成新颖图像的自编码器。接下来，您将了解在实现神经类型转移之前欺骗模型的对抗性攻击。最后，您将实现一个自编码器来生成深度假图像。

[第 12 章](80339e7c-1876-4745-8b2a-813b961093a1.xhtml)，*使用 GANs* 生成图像，首先让你深入了解 GANs 的工作原理。接下来，您将实现假面部图像生成，以及使用 GANs 生成感兴趣的图像。

[第十三章](449eb40d-52e6-4f6d-9035-2518afc1dc90.xhtml)、*高级 GANs 操控图像*，将图像操控提升到一个新的高度。您将实现 GANs 来将对象从一个类转换到另一个类，从草图生成图像，并操作自定义图像，以便我们可以生成特定样式的图像。在本章结束时，你可以自信地使用自编码器和 GANs 的组合来执行图像操作。

[第 14 章](cc4feb44-d11c-4e00-8ccc-e24ff802500c.xhtml)，*用最少的数据点进行训练*，为你学习利用其他技术与计算机视觉技术相结合奠定基础。您还将了解如何根据最小训练数据点和零训练数据点分类图像。

[第 15 章](f31e7904-19a9-4ab3-8ab6-90b1596eebc6.xhtml)，*结合计算机视觉和自然语言处理技术*，为您提供各种自然语言处理技术的工作细节，如文字嵌入、LSTM、变形器，您将使用这些技术实现图像字幕、OCR 和变形器目标检测等应用。

[第 16 章](1a2bfda9-9211-4ef5-9d8e-104eac954df4.xhtml)，*结合计算机视觉和强化学习*，首先让你接触到强化学习的术语，以及给一个状态赋值的方法。当你了解深度 Q 学习时，你会明白 RL 和神经网络是如何结合在一起的。通过学习，您将实现一个代理来玩 Pong 游戏，还将实现一个代理来实现一辆自动驾驶汽车。

[第 17 章](7d318833-5c7f-44fe-ada5-ed1aa8f58e39.xhtml)，*将模型投入生产*，描述了将模型投入生产的最佳实践。在将模型转移到 AWS 公共云之前，您将首先了解如何在本地服务器上部署模型。

[第 18 章](10c383c5-5c46-4d64-ab9c-9832ef3a3dae.xhtml)，*使用 OpenCV 实用程序进行图像分析*，详细介绍了创建 5 个有趣应用程序的各种 OpenCV 实用程序。通过本章，您将了解有助于深度学习的实用程序，以及在内存或推理速度受到相当大限制的情况下可以替代深度学习的实用程序。

# 从这本书中获得最大收益

| **书中涵盖的软件/硬件** | **操作系统要求** |
| 最低 128 GB 存储
最低 8 GB 内存
英特尔 i5 处理器或更好的处理器
英伟达 8+ GB 显卡–gtx 1070 或更好的显卡
最低 50 Mbps 互联网速度 | Windows、Linux 和 macOS |
| Python 3.6 及以上版本 | Windows、Linux 和 macOS |
| PyTorch 1.7 | Windows、Linux 和 macOS |
| Google Colab(可以在任何浏览器中运行) | Windows、Linux 和 macOS |

请注意，书中几乎所有的代码都可以使用 Google Colab 运行，只需在 GitHub 的每个章节笔记本上点击**打开 Colab** 按钮即可。

如果你使用的是这本书的数字版本，我们建议你自己输入代码或者通过 GitHub 库获取代码(链接见下一节)。这样做将帮助您避免任何与复制和粘贴代码相关的潜在错误。

## 下载示例代码文件

你可以从 GitHub 的 https://GitHub . com/packt publishing/Modern-Computer-Vision-with-py torch 下载本书的示例代码文件。如果代码有更新，它将在现有的 GitHub 库中更新。

我们在也有丰富的书籍和视频目录中的其他代码包。看看他们！

## 下载彩色图像

我们还提供了一个 PDF 文件，其中有本书中使用的截图/图表的彩色图像。可以在这里下载:[https://static . packt-cdn . com/downloads/9781839213472 _ color images . pdf](https://static.packt-cdn.com/downloads/9781839213472_ColorImages.pdf)。

## 使用的惯例

本书通篇使用了许多文本约定。

`CodeInText`:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪 URL、用户输入和 Twitter 句柄。下面是一个例子:“除了我们之前看到的`train`对象，我们正在创建一个名为`val`的`FMNISTDataset`类的对象。”

代码块设置如下:

```py
# Crop image
img = img[50:250,40:240]
# Convert image to grayscale
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# Show image
plt.imshow(img_gray, cmap='gray')
```

当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:

```py
def accuracy(x, y, model):
    model.eval() # <- let's wait till we get to dropout section
    # get the prediction matrix for a tensor of `x` images
    prediction = model(x)
    # compute if the location of maximum in each row coincides
    # with ground truth
    max_values, argmaxes = prediction.max(-1)
    is_correct = argmaxes == y
    return is_correct.cpu().numpy().tolist()
```

**Bold** :表示一个新术语、一个重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词出现在文本中，如下所示。下面是一个例子:“我们将在一个
时间使用一个**批次**应用梯度下降(在前馈通过之后)，直到我们在一个训练时期内用尽所有数据点为止。”

警告或重要提示如下所示。

提示和技巧是这样出现的。

# 取得联系

我们随时欢迎读者的反馈。

**总体反馈**:如果您对这本书的任何方面有疑问，请在邮件主题中提及书名，并在`customercare@packtpub.com`发送电子邮件给我们。

**勘误表**:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请访问 www.packtpub.com/support/errata，选择您的图书，点击勘误表提交表格链接，并输入详细信息。

**盗版**:如果您在互联网上遇到我们作品的任何形式的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过`copyright@packt.com`联系我们，并提供材料链接。

**如果你有兴趣成为一名作家**:如果有你擅长的主题，并且你有兴趣写书或投稿，请访问 authors.packtpub.com。

## 复习

请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们 Packt 可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！

更多关于 Packt 的信息，请访问[packt.com](http://www.packt.com/)。