# 十七、将模型移动到生产环境

将一个模型转移到生产环境中是向外部团体使用我们的模型迈出的一步。我们应该向世界展示我们的模型，并开始根据真实的、看不见的输入进行预测。

仅有一个训练有素的 PyTorch 模型来进行部署是不够的。我们需要额外的服务器组件来创建从真实世界到 PyTorch 模型再回到真实世界的通信通道。重要的是，我们知道如何创建一个 API(用户可以通过它与模型进行交互)，将它包装为一个自包含的应用程序(以便它可以部署在任何计算机上)，并将其发送到云——以便任何拥有所需 URL 和凭证的人都可以与模型进行交互。要成功地将模型转移到生产中，所有这些步骤都是必要的。在本章中，我们将部署一个简单的应用程序，它可以从互联网上的任何地方访问。我们还将了解如何部署**时尚 MNIST** ( **FMNIST** )模型，并让任何用户上传他们想要分类并获取结果的图片。

本章将涵盖以下主题:

*   理解 API 的基础知识
*   在本地服务器上创建 API 并进行预测
*   将 API 迁移到云中

# 理解 API 的基础知识

到目前为止，我们知道如何为各种任务创建深度学习模型。它接受/返回张量作为输入/输出。但是像客户/最终用户这样的局外人只会谈论图像和类。此外，他们希望通过与 Python 无关的通道发送和接收输入/输出。互联网是最容易沟通的渠道。因此，对于客户端来说，最好的部署场景是我们可以建立一个公开的 URL，并要求他们在那里上传他们的图像。一个这样的范例被称为**应用编程接口** ( **API** )，它拥有标准协议，通过互联网接受输入和发布输出，同时将用户从如何处理输入或生成输出中抽象出来。

API 中的一些常见协议是 POST、GET、PUT 和 DELETE，它们作为**请求**由客户端连同相关数据一起发送到主机服务器。基于请求和数据，服务器执行相关的任务，并以**响应**的形式返回适当的数据——客户端可以在它们的下游任务中使用。在我们的例子中，客户端将发送一个 POST 请求，其中包含一幅服装图片作为文件附件。我们应该保存文件，处理它，并返回适当的 FMNIST 类作为对请求的响应，我们的工作就完成了。

请求是通过互联网发送的有组织的数据包，用于与 API 服务器通信。通常，请求中的组件如下:

*   **端点 URL** :这将是 API 服务的地址。例如，`https://www.packtpub.com/`将是一个连接到 Packt Publishing 服务并浏览其最新图书目录的端点。
*   **头集合**:该信息帮助 API 服务器返回输出；如果头部包含客户机在移动设备上的信息，那么 API 可以返回一个 HTML 页面，其布局是移动设备友好的。
*   **查询的集合**，以便只获取服务器数据库中的相关项目。例如，在前面的例子中，搜索字符串`PyTorch`将只返回 PyTorch 相关的书籍。(在本章中，我们将不处理查询，因为对图像的预测不需要查询-它需要文件名。)
*   **可以上传到服务器的文件列表**，或者在我们的情况下，用于进行深度学习预测。

是一个计算机软件项目，提供了一个库和命令行工具，用于使用各种网络协议传输数据。它是调用 API 请求并获得响应的最轻量级、最常用和最简单的应用程序之一。

我们将使用一个名为`Fast-API`的现成 Python 模块，它将使我们能够完成以下任务:

1.  设置通信 URL。
2.  当输入发送到 URL 时，接受来自各种环境/格式的输入。
3.  将每种形式的输入转换为机器学习模型需要作为输入的精确格式。
4.  用经过训练的基于深度学习的模型进行预测。
5.  将预测转换成正确的格式，并用预测响应客户的请求。

我们将以 FMNIST 分类器为例来演示这些概念。

在理解了基本设置和代码之后，您可以为任何类型的深度学习任务创建 API，并通过本地机器上的 URL 提供预测。虽然这是创建应用程序的逻辑终点，但同样重要的是，我们要将它部署在任何无法访问我们的计算机或模型的人都可以访问的地方。

在接下来的两节中，我们将介绍如何将应用程序包装在一个自包含的 Docker 映像中，该映像可以在云上的任何地方发布和部署。一旦准备好 Docker 映像，就可以从它创建一个容器，并部署在任何主要的云服务提供商上，因为他们都接受 Docker 作为标准输入。我们将在本章的最后一节具体介绍在一个**亚马逊 Web 服务** ( **AWS** ) **弹性计算云** ( **EC2** )实例上部署 FMNIST 分类器的例子。在下一节中，让我们使用 Python 库 FastAPI 来创建 API，并验证我们可以直接从终端进行预测(无需 Jupyter 笔记本)。

# 在本地服务器上创建 API 并进行预测

在本节中，我们将学习在本地服务器上进行预测(这与云无关)。概括地说，这包括以下步骤:

1.  安装 FastAPI
2.  创建接受传入请求的路由
3.  将传入请求保存在磁盘上
4.  加载所请求的图像，然后用训练好的模型进行预处理和预测
5.  对结果进行后处理，并将预测作为对同一传入请求的响应发回

All of the steps in this section are summarized as a video walk-through here: [https://tinyurl.com/MCVP-Model2FastAPI](https://tinyurl.com/MCVP-Model2FastAPI).

让我们在下面的小节中开始安装 FastAPI。

## 安装 API 模块和依赖项

由于 FastAPI 是一个 Python 模块，我们可以使用`pip`进行安装，并准备编码一个 API。我们现在将打开一个新的终端并运行以下命令:

```py
$pip install fastapi uvicorn aiofiles jinja2 
```

我们已经安装了 FastAPI 需要的几个依赖项。`uvicorn`是一个最小的底层服务器/应用程序接口，用于设置 API。`aiofiles`使服务器能够与请求异步工作，比如同时接受和响应多个独立的并行请求。这两个模块是 FastAPI 的依赖项，我们不会直接与它们交互。

让我们在下一节中创建所需的文件并对它们进行编码。

## 为图像分类器服务

第一步是建立一个文件夹结构，如下所示:

![](img/ba8b8a49-c4e7-439d-b873-f435a178a831.png)

设置非常简单，如下所示:

*   `files`文件夹将作为接收请求的下载位置。
*   `fmnist.weights.pth`包含我们训练的 FMNIST 模型的权重。
*   `fmnist.py`将包含加载权重、接受输入图像、预处理、预测和后处理预测的逻辑。
*   `server.py`将包含 FastAPI 功能，可以建立一个 URL，接受来自 URL 的客户端请求，发送/接收来自`fmnist.py`的输入/输出，并发送输出作为对客户端请求的响应。

请注意:
`files`文件夹是空的，仅用于存储上传的文件。
我们假设训练模型的权重为`fmnist.weights.pth`。

现在让我们来了解一下`fmnist.py`和`server.py`的构成和编码。

### fmnist.py

如前所述，`fmnist.py`文件应该具有加载模型并返回给定图像预测的逻辑。

我们已经熟悉了如何创建 PyTorch 模型。该类唯一的附加组件是`predict`方法，它用于对图像进行任何必要的预处理，并对结果进行后处理。

在下面的代码中，我们首先创建构成模型架构的模型类，它通过`torch.load`用最优权重初始化:

```py
from torch_snippets import *

device = 'cuda' if torch.cuda.is_available() else 'cpu'

class FMNIST(nn.Module):
    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 
    'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
    def __init__(self, fpath='fmnist.weights.pth'):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(28 * 28, 1000),
            nn.ReLU(),
            nn.Linear(1000, 10)
        ).to(device)
        self.model.load_state_dict(torch.load(fpath))
        logger.info('Loaded FMNIST Model')
```

下面的代码块突出显示了`forward`方法:

```py
@torch.no_grad() 
def forward(self, x):
    x = x.view(1, -1).to(device)
    pred = self.model(x)
    pred = F.softmax(pred, -1)[0]
    conf, clss = pred.max(-1)
    clss = self.classes[clss.cpu().item()]
    return conf.item(), clss
```

下面的代码块突出显示了进行必要的预处理和后处理的`predict`方法:

```py
def predict(self, path):
    image = cv2.imread(path,0)
    x = np.array(image)
    x = cv2.resize(x, (28,28))
    x = torch.Tensor(255 - x)/255.
    conf, clss = self.forward(x)
    return {'class': clss, 'confidence': f'{conf:.4f}'}
```

在`__init__`方法中，我们正在初始化模型并加载预训练的权重。在`forward`方法中，我们通过模型传递图像并获取预测。在`predict`方法中，我们从预定义的路径加载图像，在通过模型的`forward`方法之前对图像进行预处理，并在返回预测类及其置信度的同时将输出包装在字典中。

### server.py

这是 API 中连接用户请求和 PyTorch 模型的代码部分。让我们一步一步地创建文件:

1.  加载库:

```py
import os, io
from fmnist import FMNIST
from PIL import Image
from fastapi import FastAPI, Request, File, UploadFile
```

`FastAPI`是将用于创建 API 的基本服务器类。

`Request`、`File`和`UploadFile`是客户端请求和它们将上传的文件的代理占位符。要了解更多细节，我们鼓励您阅读官方的 FastAPI 文档。

2.  加载模型:

```py
# Load the model from fmnist.py
model = FMNIST()
```

3.  创建一个`app`模型，它可以为我们提供上传和显示的 URL:

```py
app = FastAPI()
```

4.  在`"/predict"`创建一个 URL，这样客户端就可以向`"<hosturl>/predict"`发送`POST`请求(我们将在下一节了解服务器`<hosturl>`，并接收响应:

```py
@app.post("/predict")
def predict(request: Request, file:UploadFile=File(...)):
    content = file.file.read()
    image = Image.open(io.BytesIO(content)).convert('L')
    output = model.predict(image)
    return output
```

就是这样！我们有所有的组件来利用我们的图像分类器通过我们的本地服务器进行预测。让我们设置服务器并在本地服务器上做一些预测。

### 运行服务器

现在我们已经设置好了所有的组件，我们准备运行服务器。打开一个新的终端和`cd`包含`fmnist.py`、`server.py`的文件夹:

1.  运行服务器:

```py
$ uvicorn server:app
```

您将看到类似这样的消息:

![](img/3130518f-c0d6-47c4-afd1-bd6e25ec38d9.png)

`Uvicorn running on ...`消息表明服务器已经启动并正在运行。

2.  为了获取预测，我们将在终端中运行以下命令来获取对出现在`/home/me/Pictures/shirt.png`中的样本图像的预测:

```py
$ curl -X POST "http://127.0.0.1:8000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@/home/me/Pictures/shirt.png;type=img/png"
```

前面一行代码的主要组件如下:

*   **API 协议**:我们正在调用的协议是`POST`，表示要将自己的数据发送给服务器。
*   **URL–服务器地址**:服务器主机 URL 为`http://127.0.0.1:8000` `/`(为本地服务器，`8000`为默认端口)`/predict/`为客户端创建`POST`请求的路径；未来的客户必须将他们的数据上传到 URL-`http://127.0.0.1:8000/predict`。

*   **报头**:请求包含了`-H`标志形式的组件。这些解释了附加信息，例如:
    *   输入内容类型是什么—`multipart/form-data`——这是 API 术语，表示输入数据是文件形式的*。*
    *   期望的输出类型是什么-`application/json`-这意味着 JSON 格式。还有其他格式，如 XML、text 和 octet-stream，根据所生成的输出的复杂程度而定。
*   **文件**:最后一个`-F`标志指向我们要上传的文件所在的位置，以及它的类型。

一旦我们运行了前面的代码，输出字典将在终端中打印出来:

![](img/a135f893-559d-4e8c-96fc-257e84cecb80.png)

我们现在可以从本地服务器获取模型预测。在下一节中，我们将着眼于从云中获取模型预测，以便任何用户都可以获得模型预测。

# 将 API 迁移到云中

到目前为止，我们已经了解了如何在本地服务器上进行预测(`http://127.0.0.1`是本地服务器的 URL，在 web 上无法访问)——因此，只有本地机器的所有者才能使用该模型。在本节中，我们将了解如何将这个模型迁移到云中，以便任何人都可以使用图像进行预测。

一般来说，公司在冗余机器中部署服务以确保可靠性，并且对云提供商提供的硬件几乎没有控制。跟踪所有文件夹及其代码，或者复制粘贴所有代码，然后安装所有依赖项，确保代码在新环境中按预期工作，并在所有云机器上转发端口，这并不方便。对于每台新机器上的相同代码，需要遵循太多的步骤。重复这些步骤对开发人员来说是浪费时间，而且这样的过程很容易出错。

我们宁愿安装一个包含所有内容的包，也不愿安装多个单独的包(比如运行应用程序所需的单独模块和代码)并在以后连接它们。因此，我们能够将整个代码库和模块打包到单个包(类似于 Windows 中的`.exe`文件)中变得很重要，这样该包就可以用很少的一个命令来部署，并且仍然确保它在所有硬件上完全一样地工作。为此，我们需要学习如何使用 Docker——它本质上是一个带有代码的精简操作系统。创建的 Docker 容器是轻量级的，将只执行我们希望它们执行的任务。在我们的示例中，我们将创建的 Docker 映像将运行 API 来执行预测 FMNIST 映像类的任务。但首先，让我们了解一些 Docker 术语。

## 比较 Docker 容器和 Docker 图像

Docker 映像是一个标准的软件单元，它打包了代码及其所有依赖关系。这样，应用程序可以快速可靠地从一个计算环境运行到另一个计算环境。Docker 映像是一个轻量级的、独立的、可执行的软件包，包括运行应用程序所需的一切:代码、运行时、系统工具、系统库和设置。

一个 **Docker 容器**是映像的快照，它将在需要部署的任何地方被实例化。我们可以从单个映像创建任意数量的 Docker 映像副本，它们都应该执行相同的任务。将图像视为父副本，将容器视为子副本。

概括地说，我们将执行以下任务:

1.  创建 Docker 图像。用它创建一个 Docker 容器并测试它。
2.  将 Docker 映像推送到云端。
3.  在云上构建 Docker 容器。
4.  在云上部署 Docker 容器。

## 创建 Docker 容器

在上一节中，我们构建了一个 API，它获取一个图像并返回图像的类别以及与本地服务器上的图像类别相关联的概率。现在，是时候将我们的 API 打包成一个可以在任何地方运输和部署的包了。

Ensure Docker is installed on your machine. You can refer to [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/) for instructions on the installation.

创建 Docker 容器的过程有四个步骤:

1.  创建一个`requirements.txt`文件。
2.  创建 Dockerfile 文件。
3.  建立码头工人形象。
4.  从映像创建一个 Docker 容器并测试它。

The code in the following sections is also summarized as a video walkthrough here: [https://tinyurl.com/MCVP-Model2FastAPI](https://tinyurl.com/MCVP-Model2FastAPI). The relevant part of this section starts at the 2-minute mark in the video.

我们现在将浏览并理解这四个步骤，在下一节中，我们将学习如何将映像发送到 AWS 服务器。

### 创建 requirements.txt 文件

我们需要告诉 Docker 镜像安装哪些 Python 模块来运行应用程序。`requirements.txt`文件包含所有这些 Python 模块的列表:

1.  打开终端，进入包含`fmnist.py`、`server.py`的文件夹。接下来，我们将创建一个空白虚拟环境，并在本地终端的根文件夹中激活它:

```py
$ python3 -m venv fastapi-venv
$ source fastapi-env/bin/activate

```

我们创建空白虚拟环境的原因是为了确保*环境中只安装了*所需的模块，这样在发货时，我们就不会浪费宝贵的空间。

2.  安装所需的软件包(`fastapi`、`uvicorn`、`aiofiles`、`torch`和`torch_snippets`，以运行 FMNIST 应用程序:

```py
$ pip install fastapi uvicorn aiofiles torch torch_snippets
```

3.  在同一个终端中，运行以下命令来安装所有必需的 Python 模块:

```py
$ pip freeze > requirements.txt
```

前面的代码将所有 Python 模块及其对应的版本号提取到`requirements.txt`文件中，该文件将用于在 Docker 映像中安装依赖项:

![](img/bfe87240-0ec9-4f8e-a23c-d137eca34ae3.png)

我们可以打开文本文件，它看起来类似于前面的截图。现在我们已经有了所有的先决条件，让我们在下一节创建 Dockerfile。

### 创建 Dockerfile 文件

正如上一节所介绍的，Docker 映像是一个自包含的应用程序，拥有自己的操作系统和依赖项。给定一个计算平台(比如 EC2 实例)，映像可以独立工作，执行它被设计来执行的任务。为此，我们需要为 Docker 应用程序提供启动应用程序所需的指令——依赖项、代码和命令。让我们在根目录下一个名为`Dockerfile`的文本文件中创建这些指令，这个根目录包含我们的 FMINST 项目的`server.py`、`fmnist.py`——我们已经在创建项目文件夹后放置了这些指令。按照惯例，该文件需要命名为`Dockerfile`(无扩展名)。文本文件的内容如下:

```py
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7
COPY ./requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt
WORKDIR /app
COPY . /app
EXPOSE 5000
CMD ["uvicorn", "server:app", "--host", "0.0.0.0"]
```

让我们一步步理解前面的代码:

1.  `FROM`正在指示使用哪个操作系统库。`tiangolo/uvicorn-gunicorn-fastapi:python3.7`位置是 Docker 从互联网解析的一个地址，它获取一个已经安装了 Python 和其他 FastAPI 模块的基础映像。
2.  接下来，我们复制我们创建的`requirements.txt`文件。这提供了我们想要安装的包。在下一行中，我们要求图像`pip install`包。
3.  `WORKDIR`是我们的应用程序将要运行的文件夹。因此，我们在 Docker 映像中创建了一个名为`/app`的新文件夹，并将根文件夹的内容复制到映像的`/app`文件夹中。
4.  最后，我们像上一节一样运行服务器。

这样，我们就建立了一个蓝图，从头开始创建一个全新的操作系统和文件系统(把它想象成一个新的 Windows installable CD)，它将只包含我们指定的代码，并且只运行一个应用程序，即 FastAPI。

### 构建 Docker 映像并创建 Docker 容器

注意，到目前为止，我们只创建了 Docker 映像的蓝图。让我们构建图像，并用它创建一个容器。

从同一终端运行以下命令(我们位于包含应用程序文件的根目录中):

1.  构建 Docker 映像，并将其标记为`fmnist:latest`:

```py
$ docker build -t fmnist:latest .
```

在一长串输出之后，我们得到以下内容，告诉我们映像已经构建好了:

![](img/dca2869d-b9d7-4c87-97ef-113f39ea9375.png)

我们已经成功地创建了一个名为`fmnist:latest`的 Docker 映像(其中`fmnist`是映像名，`latest`是我们给的一个标签，表示它的版本号)。Docker 在系统中维护一个注册表，所有这些图像都可以从该注册表中访问。这个 Docker 注册表现在包含一个独立的映像，其中包含运行 FMNIST API 的所有代码和逻辑。

我们总是可以通过在命令提示符下键入`$ docker image ls`来检查 Docker 注册表:

![](img/d4ffad5c-2a28-4d0e-a90a-31c846053360.png)

2.  在本地机器上运行构建好的映像，将端口`5000`从映像内部转发到端口`5000`。最后一个参数是从图像创建的容器的名称:

```py
$ docker run -p 5000:5000 fmnist:latest
```

Port forwarding is important. Often, we don't have a say on which ports the cloud is exposing. Hence, as a matter of demonstration, even though our `uvicorn` model created a `5000` port for the `POST` operation, we are still using Docker's functionality to route external requests from `5000` to `5000`, which is where `uvicorn` is listening.

这将给出最后几行的提示，如下所示:

![](img/83c73be6-eb6e-4a13-b391-04b0021d468f.png)

3.  现在，从一个新的终端运行一个`curl`请求，并访问上一节中描述的 API，但是这一次，应用程序由 Docker 提供服务:

![](img/d4f59c43-be8b-4c57-87d0-e12bf6ec52fa.png)

尽管到目前为止我们还没有将任何东西迁移到云中，但是将 API 封装在 Docker 中使我们再也不用担心`pip install`或者复制粘贴代码了。接下来，我们将把它交付给云提供商，并向全世界发布这款应用。

现在，您可以将图像发送到任何装有 Docker 的计算机上。不管我们将它装载到什么类型的计算机上，调用`docker run`总是会创建一个容器，它将完全按照我们想要的方式工作。我们不再需要担心`pip install`或者复制粘贴代码。

## 在云端运输和运行 Docker 容器

我们将依靠 AWS 来满足我们的云需求。出于我们的目的，我们将使用 AWS 的两个免费产品:

*   **弹性容器注册表** ( **ECR** ):在这里，我们将存储我们的 Docker 图像。
*   这里，我们将创建一个 Linux 系统来运行我们的 API Docker 映像。

对于这一部分，让我们只关注它的 ECR 部分。下面是我们将 Docker 映像推送到云的步骤的概要:

1.  在本地机器上配置 AWS。
2.  在 AWS ECR 上创建 Docker 存储库，并推送`fmnist:latest`映像。
3.  创建一个 EC2 实例。
4.  在 EC2 实例上安装依赖项。
5.  在 EC2 实例上创建并运行 Docker 映像。

The code in the following sections is also summarized as a video walkthrough here: [https://tinyurl.com/MCVP-FastAPI2AWS](https://tinyurl.com/MCVP-FastAPI2AWS).

让我们实现前面的步骤，在下一节中从配置 AWS 开始。

### 配置 AWS

我们将从命令提示符登录 AWS，并推送我们的 Docker 映像。让我们一步一步来:

1.  在[https://aws.amazon.com/](https://aws.amazon.com/)创建一个 AWS 账户并登录。
2.  在本地机器上安装 AWS CLI(包含 Docker 映像)。

The AWS CLI is a command-line interface application for all Amazon services. It should be installed from the official website for your operating system first. Visit [https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html) for more details.

3.  通过在本地终端中运行`aws --version`来验证它是否已安装。
4.  配置 AWS CLI。从[https://aws.amazon.com/](https://aws.amazon.com/)处获得以下代币:
    *   `aws_account_id`
    *   访问密钥 ID
    *   秘密访问密钥
    *   地区

我们可以在 AWS 的**身份和访问管理** ( **IAM** )部分找到所有前述变量。在终端中运行`aws configure`,并在被询问时给出适当的凭证:

```py
$ aws configure
AWS Access Key ID [None]: *AKIAIOSFODNN7EXAMPLE*
AWS Secret Access Key [None]:*wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY*
Default region name [None]: *region*
Default output format [None]:*json* 
```

我们现在已经从电脑上登录了亚马逊的服务。原则上，我们可以直接从终端访问他们的任何服务。在下一节中，让我们连接到 ECR 并推送 Docker 映像。

### 在 AWS ECR 上创建 Docker 存储库并推送映像

现在，我们将创建 Docker 存储库，如下所示:

1.  配置完成后，使用以下命令登录 AWS ECR(以下代码都是一行)，在以下代码中以粗体显示的位置提供前面的区域和帐户 ID 详细信息:

```py
$ aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com

```

前面的代码行创建并连接到 Amazon cloud 中您自己的 Docker 注册中心。与本地系统中的 Docker 注册表非常相似，这是映像将要驻留的地方，但是它将位于云中。

2.  通过运行以下命令，从 CLI 创建存储库:

```py
$ aws ecr create-repository --repository-name fmnist_app

```

使用前面的代码，现在在云中创建了一个可以保存 Docker 图像的位置。

3.  通过运行以下命令来标记您的本地映像，以便当您推送映像时，它将被推送到标记的存储库。记得在下面代码的粗体部分给出您自己的`aws_accound_id`和`region`值:

```py
$ docker tag fmnist:latest aws_account_id.dkr.ecr.region.amazonaws.com/fmnist_app
```

4.  运行以下命令将本地 Docker 映像推送到云中的 AWS 存储库:

```py
$ docker push aws_account_id.dkr.ecr.region.amazonaws.com/fmnist_app

```

我们已经成功地在云中为我们的 API 创建了一个位置，并将 Docker 映像推送到这个位置。正如您现在所知道的，这个映像已经有了运行 API 的所有组件。唯一剩下的方面是在云中创建一个 Docker 容器，这样我们就成功地将我们的应用程序转移到生产环境中了！

### 创建 EC2 实例

将 Docker 映像推送到 AWS ECR 就像将代码推送到 GitHub 存储库一样。它只是驻留在一个地方，我们仍然需要用它来构建应用程序。

为此，您必须创建一个 Amazon EC2 实例来服务您的 web 应用程序:

1.  进入 AWS 管理控制台的搜索栏，搜索`EC2`。
2.  选择启动实例。
3.  您将获得一个可用实例的列表。AWS 在免费层提供了许多实例。我们在这里选择了具有 20 GB 空间的 Amazon Linux 2 AMI - t2.micro 实例(您也可以使用其他实例，但要记得相应地更改配置)。

4.  在配置实例创建时，在 Configure Security Group 部分，添加一个带有自定义 TCP 集的规则，并将端口范围设置为`5000`(因为我们已经在 Docker 映像中公开了端口`5000`，如下所示:

![](img/b02b5fb0-dae5-4da6-9721-42bb7e6e6b26.png)

5.  在最后一步的**启动实例**弹出窗口中(见下面的截图)，创建一个新的密钥对(这将下载一个`.pem`文件，这是登录实例所需要的)。这就像一个密码，所以不要丢失这个文件:

![](img/f363c675-e0be-4fc7-9a99-650ecc95a4b3.png)

6.  将`.pem`文件移动到一个安全的位置，并通过运行`chmod 400 fastapi.pem`更改其权限。

此时，您应该在 EC2 仪表板中看到一个实例正在运行:

![](img/3e623198-9b2c-47c9-ae99-73e56568171c.png)

7.  复制 EC2 实例名称，如下所示:

```py
ec2-18-221-11-226.us-east-2.compute.amazonaws.com
```

8.  在本地终端中使用以下命令登录到 EC2 实例:

```py
$ ssh -i fastapi.pem ec2-user@ec2-18-221-11-226.us-east-2.compute.amazonaws.com
```

我们已经创建了一个具有必要空间和操作系统的 EC2 实例。此外，我们能够从机器上公开端口`8000`,并且还可以记录该机器的公共 URL(该 URL 将被客户端用于发送`POST`请求)。最后，我们成功地使用下载的`.pem`文件登录了它，就像对待其他可以安装软件的机器一样对待 EC2 机器。

### 提取图像并构建 Docker 容器

让我们安装在 EC2 机器上运行 Docker 映像的依赖项，然后我们就可以运行 API 了。以下命令都需要在我们在上一节中登录的 EC2 控制台中运行(上一节的*s*步骤 8 ):

1.  在 Linux 机器上安装和配置 Docker 映像:

```py
$ sudo yum install -y docker
$ sudo groupadd docker
$ sudo gpasswd -a ${USER} docker
$ sudo service docker restart

```

`groupadd`和`gpasswd`确保 Docker 拥有运行所需的所有权限。

2.  像前面一样，在 EC2 实例中配置 AWS，并重新启动机器:

```py
$ aws configure
AWS Access Key ID [None]: *AKIAIOSFODNN7EXAMPLE*
AWS Secret Access Key [None]:*wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY*
Default region name [None]: *us-west-2*
Default output format [None]:*json* $ reboot 
```

3.  使用以下命令从本地终端再次登录到实例:

```py
$ ssh -i fastapi.pem ec2-user@ec2-18-221-11-226.us-east-2.compute.amazonaws.com
```

4.  现在，从 EC2 登录控制台(安装了 Docker)登录到 AWS ECR(在下面的代码中更改以粗体显示的区域):

```py
$ aws ecr get-login --region region --no-include-email

```

5.  复制前面代码的输出，然后粘贴并在命令行中运行它。一旦您成功登录到 AWS ECR，您将在控制台中看到**登录成功**。
6.  从 AWS ECR 中提取 Docker 图像:

```py
$ docker pull aws_account_id.dkr.ecr.region.amazonaws.com/fmnist_app:latest

```

7.  最后，在 EC2 机器上运行提取的 Docker 映像:

```py
docker run -p 5000:5000 aws_account_id.dkr.ecr.region.amazonaws.com/fmnist_app

```

我们在 EC2 上运行我们的 API。我们所要做的就是获得机器的公共 IP 地址，并用这个地址代替`127.0.0.1`运行`curl`请求。您可以在页面右侧的 EC2 仪表板上找到该地址:

![](img/b0f09996-610a-43ae-a779-c41e7deb0f62.png)

8.  现在，您可以从任何一台计算机上调用一个`POST`请求，EC2 实例将对其做出响应，预测我们上传的服装图像的类型:

```py
$ curl -X POST "http://54.229.16.169:5000/predict" -H "accept: application/json" -H "Content-Type: multipart/form-data" -F "file=@/home/me/Pictures/shirt.png;type=img/png"
```

上述代码会产生以下输出:

```py
{"class":"Coat","confidence":"0.6488"}
```

在本节中，我们能够安装 EC2 的依赖项，提取 Docker 映像，并运行 Docker 容器，使任何具有 URL 的用户能够对新映像进行预测。

# 摘要

在这一章中，我们学习了将模型转移到生产中还需要哪些额外的步骤。我们学习了什么是 API 以及它的组件是什么。在创建一个 API 之后，通过使用 FastAPI，我们浏览了创建 API 的 Docker 映像的核心步骤。使用 AWS，我们在云中创建了自己的 Docker 注册中心，并逐步将我们的 Docker 映像推送到那里。我们看到了创建 EC2 实例和安装所需的库，从 ECR 中提取 Docker 映像，从它构建 Docker 容器，并部署它供任何用户进行预测。

在下一章，也是最后一章，我们将学习 OpenCV，它有一些实用程序可以帮助解决一些受限环境中与图像相关的问题。我们将通过五个不同的用例来了解如何利用 OpenCV 进行图像分析。学习 OpenCV 的功能将进一步增强我们的计算机视觉技能。