# 十一、嵌入式计算机视觉：在 Raspberry Pi 上运行 OpenCV 程序

Abstract

嵌入式计算机视觉是计算机视觉的一个非常实用的分支，它关注于开发或修改视觉算法，以在嵌入式系统上运行，嵌入式系统是指小型移动计算机，如智能手机处理器或爱好板。嵌入式计算机视觉系统的两个主要考虑因素是明智地使用处理能力和低电池功耗。作为嵌入式计算系统的一个例子，我们将考虑 Raspberry Pi(图 11-1)，这是一款基于 ARM 处理器的小型开源计算机，由于其易用性、多功能性以及令人惊讶的低成本(尽管具有良好的构建和支持质量),在爱好者和研究人员中迅速受到欢迎。

嵌入式计算机视觉是计算机视觉的一个非常实用的分支，它关注于开发或修改视觉算法，以在嵌入式系统上运行，嵌入式系统是指小型移动计算机，如智能手机处理器或爱好板。嵌入式计算机视觉系统的两个主要考虑因素是明智地使用处理能力和低电池功耗。作为嵌入式计算系统的一个例子，我们将考虑 Raspberry Pi(图 [11-1](#Fig1) )，这是一款基于 ARM 处理器的小型开源计算机，由于其易用性、多功能性以及令人惊讶的低成本(尽管构建和支持质量良好)，在爱好者和研究人员中迅速受到欢迎。

## 树莓派

![A978-1-4302-6080-6_11_Fig1_HTML.jpg](A978-1-4302-6080-6_11_Fig1_HTML.jpg)

图 11-1。

The Raspberry Pi board

Raspberry Pi 是一台小型计算机，可以从 SD 存储卡运行基于 Linux 的操作系统。它有一个 700 MHz 的 ARM 处理器和一个小型的 Broadcom VideoCore IV 250 MHz GPU。CPU 和 GPU 共享 512 MB 的 SDRAM 内存，您可以根据您的使用模式更改两者之间的内存共享。如图 [11-1](#Fig1) 所示，Pi 具有一个以太网、一个 HDMI、两个 USB 2.0 端口、8 个通用输入/输出引脚和一个 UART 以与其他设备交互。最近还发布了 5 MP 相机板，以促进 Pi 在小规模计算机视觉应用中的使用。这个相机板有它自己的特殊并行连接器；因此，它有望支持比连接到 USB 端口之一的网络摄像头更高的帧速率。Pi 也非常省电——它可以通过电脑的 USB 端口或 iPhone 的 USB 壁式充电器供电！

## 设置您的新树莓派

因为 Pi 只是一个处理器，上面有各种通信端口和引脚，如果你打算购买一个，请确保订购时附带所有必需的附件。这些主要包括连接器电缆:

*   用于连接互联网的以太网电缆
*   USB-A 到 USB-B 转换器电缆，用于从通电的 USB 端口供电
*   用于连接显示器的 HDMI 电缆
*   摄像头模块(可选)
*   USB 扩展器集线器如果您计划将两个以上的 USB 设备连接到 Pi
*   容量至少为 4 GB 的 SD 存储卡，用于安装操作系统和其他程序

虽然可以在 Pi 上安装几个基于 Linux 的操作系统，但是推荐初学者使用 Raspbian(本文撰写时的最新版本“wheezy ”),它是针对 Pi 优化的 Debian 版本。本章的其余部分将假设您已经在 Pi 上安装了 Raspbian，因为它开箱即用，而且有大量的社区支持。一旦你安装了操作系统并连接了显示器、键盘和鼠标，它就变成了一台功能齐全的电脑！典型的基于 GUI 的设置如图 [11-2](#Fig2) 所示。

![A978-1-4302-6080-6_11_Fig2_HTML.jpg](A978-1-4302-6080-6_11_Fig2_HTML.jpg)

图 11-2。

Raspberry Pi connected to keyboard, mouse, and monitor—a complete computer!

### 在码头上安装 Raspbian

您将需要一张容量至少为 4 GB 的空白 SD 卡，并能访问一台计算机来完成这个简单的过程。如果你是第一次使用，建议你在 [`www.raspberrypi.org/downloads`](http://www.raspberrypi.org/downloads) 使用专门打包的新开箱软件(NOOBS)。使用它的详细说明可以在 [`www.raspberrypi.org/wp-content/uploads/2012/04/quick-start-guide-v2_1.pdf`](http://www.raspberrypi.org/wp-content/uploads/2012/04/quick-start-guide-v2_1.pdf) 的快速入门指南中找到。本质上，您:

*   将 NOOBS 软件下载到您的计算机上
*   在 SD 卡上解压
*   将 SD 卡插入 Pi，并使用分别连接到 USB 和 HDMI 的键盘和显示器启动
*   遵循屏幕上的简单说明，确保选择 Raspbian 作为要安装的操作系统

请注意，这将创建一个密码为“raspberry”的用户帐户“pi”这个帐户也有 sudo 访问相同的密码。

### 初始设置

安装 Raspbian 后，重启并按住“Shift”进入`raspi-config`设置画面，如图 [11-3](#Fig3) 所示。

*   首先，您应该使用`'expand_rootfs'`选项来使 Pi 使用您的整个存储卡。
*   您也可以使用`'memory_split'`选项更改 RAM 内存共享设置。我的建议是尽可能多地分配给 CPU，因为 OpenCV 还不支持 VideoCore GPU，所以我们最终将使用 ARM CPU 进行所有计算。
*   您还可以使用`raspi-config`中的`'boot_behavior'`选项来指定 Pi 是引导到 GUI 还是命令行。显然，维护 GUI 会占用处理能力，所以我建议您熟悉 Linux 终端并关闭 GUI。访问已经设置为引导到命令行的 Pi 的典型方法是使用 X-forwarding 通过 SSH 进入它。这实质上意味着您使用以太网连接到 Pi，并从您计算机上的终端访问 Pi 的终端。X-forwarding 意味着 Pi 将你的计算机屏幕渲染成任何窗口(例如，OpenCV `imshow()`窗口)。Adafruit 在 [`http://learn.adafruit.com/downloads/pdf/adafruits-raspberry-pi-lesson-6-using-ssh.pdf`](http://learn.adafruit.com/downloads/pdf/adafruits-raspberry-pi-lesson-6-using-ssh.pdf) `.`为首次使用 SSH 的用户提供了很好的指南

![A978-1-4302-6080-6_11_Fig3_HTML.jpg](A978-1-4302-6080-6_11_Fig3_HTML.jpg)

图 11-3。

The `raspi-config` screen

### 安装 OpenCV

因为 Raspbian 是一个 Linux 版本，以 Debian 作为它的包管理系统，安装 OpenCV 的过程与在 64 位系统上安装的过程完全相同，如第 2 章中所述。一旦你安装了 OpenCV，你就可以像在你的电脑上一样运行演示程序了。如果您将 USB 网络摄像头连接到 Pi，需要摄像头进行实时反馈的演示也可以进行。

图 [11-4](#Fig4) 显示了从 Pi 上的 USB 摄像头运行的 OpenCV 视频单应性估计演示(`cpp-example-video_homography`)。您可能还记得，这个函数跟踪帧中的角点，然后根据用户可以选择的帧找到一个变换(用绿线表示)。如果您自己运行这个演示，您会发现 Pi 中的 700 MHz 处理器不足以处理此类演示中的 640x480 帧——帧速率非常低。

![A978-1-4302-6080-6_11_Fig4_HTML.jpg](A978-1-4302-6080-6_11_Fig4_HTML.jpg)

图 11-4。

OpenCV built-in video homography demo being run on the Raspberry Pi

图 [11-5](#Fig5) 显示了 OpenCV 凸包演示(`cpp-example-convexhull`)，它选择了一组随机的点，并在 Pi 上计算出它们周围的最小凸包。

![A978-1-4302-6080-6_11_Fig5_HTML.jpg](A978-1-4302-6080-6_11_Fig5_HTML.jpg)

图 11-5。

OpenCV convex hull demo being run on the Pi

## 摄像板

树莓派 的制造商最近还发布了一个定制的相机板，以鼓励 Pi 的图像处理和计算机视觉应用。该板很小，重量只有 3 克，但它拥有一个 500 万像素的 CMOS 传感器。它使用带状电缆连接到 Pi，看起来如图 [11-6](#Fig6) 所示。

![A978-1-4302-6080-6_11_Fig6_HTML.jpg](A978-1-4302-6080-6_11_Fig6_HTML.jpg)

图 11-6。

The Raspberry Pi with the camera board attached to it

在 [`www.raspberrypi.org/camera`](http://www.raspberrypi.org/camera) 按照指导视频连接后，您需要从`raspi-config`屏幕启用它(可以在启动时按住“Shift”或在终端键入`sudo raspi-config`调出)。预装的实用程序`raspistill`和`raspivid`可分别用于捕捉静态图像和视频。他们提供了许多捕捉选项，你可以调整。你可以通过浏览 [`https://github.com/raspberrypi/userland/blob/master/host_applications/linux/apps/raspicam/RaspiCamDocs.odt`](https://github.com/raspberrypi/userland/blob/master/host_applications/linux/apps/raspicam/RaspiCamDocs.odt) 的文档来了解更多。这些应用的源代码是开源的，因此我们将看到如何使用它来使开发板与 OpenCV 进行交互。

### 相机板与 USB 相机

你可能会问，当你可以使用像你在台式电脑上使用的那种简单的 USB 相机时，为什么要使用相机板呢？两个原因:

The Raspberry Pi camera board connects to the Pi using a special connector that is designed to transfer data in parallel. This makes is faster than a USB camera   The camera board has a better sensor than a lot of other USB cameras that cost the same (or even more)  

唯一的问题是，因为该板不是 USB 设备，OpenCV 不能识别它的开箱即用。我做了一个小的 C++包装程序，通过重用我在 Raspberry Pi 论坛上找到的一些 C 代码，从相机缓冲区中抓取字节，并将它们放入 OpenCV `Mat`中。这段代码利用了相机驱动程序开发者发布的开源代码。这个程序允许你指定你要捕获的帧的大小和一个布尔标志，该标志指示捕获的帧应该是彩色的还是灰度的。相机以(YUV 颜色空间)的 Y 通道和二次采样 U 和 V 通道的形式返回图像信息。为了获得灰度图像，包装程序只需将 Y 通道设置为 OpenCV `Mat`的数据源。如果你想要颜色，事情会变得复杂(和缓慢)。为了获得彩色图像，包装程序必须执行以下步骤:

*   将 Y、U 和 V 通道复制到 OpenCV Mats 中
*   调整 U 和 V 通道的大小，因为相机返回的 U 和 V 是二次采样的
*   执行 YUV 到 RGB 转换

这些操作非常耗时，因此，如果您想要从相机板传输彩色图像，帧速率会下降。

相比之下，默认情况下，USB 摄像头捕捉的是彩色图像，你必须花费额外的时间将其转换为灰度图像。因此，除非你知道如何将相机的捕捉模式设置为灰度，否则来自 USB 相机的灰度图像比彩色图像更昂贵。

正如我们到目前为止所看到的，大多数计算机视觉应用都是基于强度进行操作的，因此只需要灰度图像。这是使用相机板而不是 USB 相机的另一个原因。让我们看看如何使用包装器代码从 Pi 相机板获取帧。注意，这个过程需要在 Pi 上安装 OpenCV。

*   如果你从`raspi-config,`开始启用你的相机，你应该已经有了与`/opt/vc/.`中的相机板接口的源代码和库，通过查看命令`raspistill`和`raspivid`是否按预期工作来确认这一点。
*   通过在终端中导航到您的主文件夹中的任何目录并运行以下命令，克隆官方的 MMAL Github 存储库以获得所需的头文件。注意，在清单 11-1 中的 CMakeLists.txt 文件中，这个目录将被称为 USERLAND_DIR，所以要确保用这个目录的完整路径替换这个文件中的 USERLAND_DIR。如果您的 Raspberry Pi 上没有安装 Git，您可以通过在终端中键入`sudo apt-get install git`来安装它。)

`git clone`[`https://github.com/raspberrypi/userland.git`T3】](https://github.com/raspberrypi/userland.git)

*   包装程序将与 CMake 构建环境一起工作。在一个单独的文件夹中(下面称为 DIR ),创建名为“src”和“include”的文件夹将代码 10-1 中的`Picam.cpp`和`cap.h`文件分别放入“src”和“include”文件夹。这些构成了包装代码
*   要使用包装器代码，创建一个简单的文件，如代码 10-1 所示的 main.cpp，从相机板获取帧，在窗口中显示它们，并测量帧速率。将文件放在“src”文件夹中
*   想法是创建一个可执行文件，使用来自`main.cpp`和`PiCapture.cpp`文件的函数和类。这可以通过使用类似代码 10-1 所示的`CMakeLists.txt`文件并将其保存在 DIR 中来完成
*   要编译和构建可执行文件，请在 DIR 中运行

`mkdir build`

`cd build`

`cmake ..`

`make`

下面是关于包装器代码的一点解释。正如您可能已经意识到的那样，包装器代码创建了一个名为`PiCapture`的类，该类的构造函数接受宽度、高度和布尔标志(true 表示抓取彩色图像)。该类还定义了一个名为`grab()`的方法，该方法返回一个 OpenCV `Mat`，其中包含适当大小和类型的抓取图像。

清单 11-1。简单的 CMake 项目展示了从 Raspberry Pi 相机板捕获帧的包装器代码

`main.cpp:`

`//Code to check the OpenCV installation on Raspberry Pi and measure frame rate`

`//Author: Samarth Manoj Brahmbhatt, University of Pennsyalvania`

`#include "cap.h"`

`#include <opencv2/opencv.hpp>`

`#include <opencv2/highgui/highgui.hpp>`

`using namespace cv;`

`using namespace std;`

`int main() {`

`namedWindow("Hello");`

`PiCapture cap(320, 240, false);`

`Mat im;`

`double time = 0;`

`unsigned int frames = 0;`

`while(char(waitKey(1)) != 'q') {`

`double t0 = getTickCount();`

`im = cap.grab();`

`frames++;`

`if(!im.empty()) imshow("Hello", im);`

`else cout << "Frame dropped" << endl;`

`time += (getTickCount() - t0) / getTickFrequency();`

`cout << frames / time << " fps" << endl;`

`}`

`return 0;`

`}`

`cap.h:`

`#include <opencv2/opencv.hpp>`

`#include "interface/mmal/mmal.h"`

`#include "interface/mmal/util/mmal_default_components.h"`

`#include "interface/mmal/util/mmal_connection.h"`

`#include "interface/mmal/util/mmal_util.h"`

`#include "interface/mmal/util/mmal_util_params.h"`

`class PiCapture {`

`private:`

`MMAL_COMPONENT_T *camera;`

`MMAL_COMPONENT_T *preview;`

`MMAL_ES_FORMAT_T *format;`

`MMAL_STATUS_T status;`

`MMAL_PORT_T *camera_preview_port, *camera_video_port, *camera_still_port;`

`MMAL_PORT_T *preview_input_port;`

`MMAL_CONNECTION_T *camera_preview_connection;`

`bool color;`

`public:`

`static cv::Mat image;`

`static int width, height;`

`static MMAL_POOL_T *camera_video_port_pool;`

`static void set_image(cv::Mat _image) {image = _image;}`

`PiCapture(int, int, bool);`

`cv::Mat grab() {return image;}`

`};`

`static void color_callback(MMAL_PORT_T *, MMAL_BUFFER_HEADER_T *);`

`static void gray_callback(MMAL_PORT_T *, MMAL_BUFFER_HEADER_T *);`

`PiCapture.cpp:`

`/*`

`* File: opencv_demo.c`

`* Author: Tasanakorn`

`*`

`* Created on May 22, 2013, 1:52 PM`

`*/`

`// OpenCV 2.x C++ wrapper written by Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <stdio.h>`

`#include <stdlib.h>`

`#include <opencv2/opencv.hpp>`

`#include "bcm_host.h"`

`#include "interface/mmal/mmal.h"`

`#include "interface/mmal/util/mmal_default_components.h"`

`#include "interface/mmal/util/mmal_connection.h"`

`#include "interface/mmal/util/mmal_util.h"`

`#include "interface/mmal/util/mmal_util_params.h"`

`#include "cap.h"`

`#define MMAL_CAMERA_PREVIEW_PORT 0`

`#define MMAL_CAMERA_VIDEO_PORT 1`

`#define MMAL_CAMERA_CAPTURE_PORT 2`

`using namespace cv;`

`using namespace std;`

`int PiCapture::width = 0;`

`int PiCapture::height = 0;`

`MMAL_POOL_T * PiCapture::camera_video_port_pool = NULL;`

`Mat PiCapture::image = Mat();`

`static void color_callback(MMAL_PORT_T *port, MMAL_BUFFER_HEADER_T *buffer) {`

`MMAL_BUFFER_HEADER_T *new_buffer;`

`mmal_buffer_header_mem_lock(buffer);`

`unsigned char* pointer = (unsigned char *)(buffer -> data);`

`int w = PiCapture::width, h = PiCapture::height;`

`Mat y(h, w, CV_8UC1, pointer);`

`pointer = pointer + (h*w);`

`Mat u(h/2, w/2, CV_8UC1, pointer);`

`pointer = pointer + (h*w/4);`

`Mat v(h/2, w/2, CV_8UC1, pointer);`

`mmal_buffer_header_mem_unlock(buffer);`

`mmal_buffer_header_release(buffer);`

`if (port->is_enabled) {`

`MMAL_STATUS_T status;`

`new_buffer = mmal_queue_get(PiCapture::camera_video_port_pool->queue);`

`if (new_buffer)`

`status = mmal_port_send_buffer(port, new_buffer);`

`if (!new_buffer || status != MMAL_SUCCESS)`

`printf("Unable to return a buffer to the video port\n");`

`}`

`Mat image(h, w, CV_8UC3);`

`resize(u, u, Size(), 2, 2, INTER_LINEAR);`

`resize(v, v, Size(), 2, 2, INTER_LINEAR);`

`int from_to[] = {0, 0};`

`mixChannels(&y, 1, &image, 1, from_to, 1);`

`from_to[1] = 1;`

`mixChannels(&v, 1, &image, 1, from_to, 1);`

`from_to[1] = 2;`

`mixChannels(&u, 1, &image, 1, from_to, 1);`

`cvtColor(image, image, CV_YCrCb2BGR);`

`PiCapture::set_image(image);`

`}`

`static void gray_callback(MMAL_PORT_T *port, MMAL_BUFFER_HEADER_T *buffer) {`

`MMAL_BUFFER_HEADER_T *new_buffer;`

`mmal_buffer_header_mem_lock(buffer);`

`unsigned char* pointer = (unsigned char *)(buffer -> data);`

`PiCapture::set_image(Mat(PiCapture::height, PiCapture::width, CV_8UC1, pointer));`

`mmal_buffer_header_release(buffer);`

`if (port->is_enabled) {`

`MMAL_STATUS_T status;`

`new_buffer = mmal_queue_get(PiCapture::camera_video_port_pool->queue);`

`if (new_buffer)`

`status = mmal_port_send_buffer(port, new_buffer);`

`if (!new_buffer || status != MMAL_SUCCESS)`

`printf("Unable to return a buffer to the video port\n");`

`}`

`}`

`PiCapture::PiCapture(int _w, int _h, bool _color) {`

`color = _color;`

`width = _w;`

`height = _h;`

`camera = 0;`

`preview = 0;`

`camera_preview_port = NULL;`

`camera_video_port = NULL;`

`camera_still_port = NULL;`

`preview_input_port = NULL;`

`camera_preview_connection = 0;`

`bcm_host_init();`

`status = mmal_component_create(MMAL_COMPONENT_DEFAULT_CAMERA, &camera);`

`if (status != MMAL_SUCCESS) {`

`printf("Error: create camera %x\n", status);`

`}`

`camera_preview_port = camera->output[MMAL_CAMERA_PREVIEW_PORT];`

`camera_video_port = camera->output[MMAL_CAMERA_VIDEO_PORT];`

`camera_still_port = camera->output[MMAL_CAMERA_CAPTURE_PORT];`

`{`

`MMAL_PARAMETER_CAMERA_CONFIG_T cam_config = {`

`{ MMAL_PARAMETER_CAMERA_CONFIG, sizeof (cam_config)}, width, height, 0, 0, width, height, 3, 0, 1, MMAL_PARAM_TIMESTAMP_MODE_RESET_STC };`

`mmal_port_parameter_set(camera->control, &cam_config.hdr);`

`}`

`format = camera_video_port->format;`

`format->encoding = MMAL_ENCODING_I420;`

`format->encoding_variant = MMAL_ENCODING_I420;`

`format->es->video.width = width;`

`format->es->video.height = height;`

`format->es->video.crop.x = 0;`

`format->es->video.crop.y = 0;`

`format->es->video.crop.width = width;`

`format->es->video.crop.height = height;`

`format->es->video.frame_rate.num = 30;`

`format->es->video.frame_rate.den = 1;`

`camera_video_port->buffer_size = width * height * 3 / 2;`

`camera_video_port->buffer_num = 1;`

`status = mmal_port_format_commit(camera_video_port);`

`if (status != MMAL_SUCCESS) {`

`printf("Error: unable to commit camera video port format (%u)\n", status);`

`}`

`// create pool form camera video port`

`camera_video_port_pool = (MMAL_POOL_T *) mmal_port_pool_create(camera_video_port, camera_video_port->buffer_num, camera_video_port->buffer_size);`

`if(color) {`

`status = mmal_port_enable(camera_video_port, color_callback);`

`if (status != MMAL_SUCCESS)`

`printf("Error: unable to enable camera video port (%u)\n", status);`

`else`

`cout << "Attached color callback" << endl;`

`}`

`else {`

`status = mmal_port_enable(camera_video_port, gray_callback);`

`if (status != MMAL_SUCCESS)`

`printf("Error: unable to enable camera video port (%u)\n", status);`

`else`

`cout << "Attached gray callback" << endl;`

`}`

`status = mmal_component_enable(camera);`

`// Send all the buffers to the camera video port`

`int num = mmal_queue_length(camera_video_port_pool->queue);`

`int q;`

`for (q = 0; q < num; q++) {`

`MMAL_BUFFER_HEADER_T *buffer = mmal_queue_get(camera_video_port_pool->queue);`

`if (!buffer) {`

`printf("Unable to get a required buffer %d from pool queue\n", q);`

`}`

`if (mmal_port_send_buffer(camera_video_port, buffer) != MMAL_SUCCESS) {`

`printf("Unable to send a buffer to encoder output port (%d)\n", q);`

`}`

`}`

`if (mmal_port_parameter_set_boolean(camera_video_port, MMAL_PARAMETER_CAPTURE, 1) != MMAL_SUCCESS) {`

`printf("%s: Failed to start capture\n", __func__);`

`}`

`cout << "Capture started" << endl;`

`}`

`CMakeLists.txt:`

`cmake_minimum_required(VERSION 2.8)`

`project(PiCapture)`

`SET(COMPILE_DEFINITIONS -Werror)`

`find_package( OpenCV REQUIRED )`

`include_directories(/opt/vc/include)`

`include_directories(/opt/vc/include/interface/vcos/pthreads)`

`include_directories(/opt/vc/include/interface/vmcs_host)`

`include_directories(/opt/vc/include/interface/vmcs_host/linux)`

`include_directories(USERLAND_DIR)`

`include_directories("${PROJECT_SOURCE_DIR}/include")`

`link_directories(/opt/vc/lib)`

`link_directories(/opt/vc/src/hello_pi/libs/vgfont)`

`add_executable(main src/main.cpp src/PiCapture.cpp)`

`target_link_libraries(main mmal_core mmal_util mmal_vc_client bcm_host ${OpenCV_LIBS})`

从现在开始，你可以使用同样的策略从相机板抓取帧——在你的源文件中包含`cam.h`,并创建一个使用你的源文件和`PiCapture.cpp`的可执行文件。

### 帧速率比较

图 [11-7](#Fig7) 显示了 USB 摄像头与摄像头板的帧率比较。使用的程序很简单；他们只是抓取帧，并在循环中使用`imshow()`显示它们。在相机板的情况下，`PiCapture`构造函数的参数列表中的布尔标志用于从彩色切换到灰度。对于 USB 摄像头，通过对彩色图像使用`cvtColor()`来获得灰度图像。

![A978-1-4302-6080-6_11_Fig7_HTML.jpg](A978-1-4302-6080-6_11_Fig7_HTML.jpg)

图 11-7。

Frame-rate tests. Clockwise from top left: Grayscale from USB camera, grayscale from camera board, color from camera board, and color from USB camera

帧率的计算和之前一样使用 OpenCV 函数`getTickCount()`和`getTickFrequency()`来完成。然而，有时在`PiCapture.cpp`进行的并行进程似乎弄乱了滴答计数，据报道相机板测得的帧速率比实际要高得多。当你自己运行程序时，你会发现这两种方法对彩色图像给出了几乎相同的帧速率(视觉上)，但从相机板抓取比使用 USB 相机对灰度图像快得多。

## 用法示例

一旦你在你的 Pi 上设置好了所有的东西，它的行为就非常像你的普通计算机，你应该能够运行你在普通计算机上运行的所有 OpenCV 代码，除了它会运行得更慢。作为使用示例，我们将检查我们在本书中开发的两种类型的对象检测器的帧速率，基于颜色的和基于 ORB 关键点的。

### 基于颜色的对象检测器

还记得我们在[第 5 章](05.html)中完善的基于颜色的目标检测器吗(清单 5-7)？让我们看看它是如何运行的 USB 摄像头与彩色图像抓取使用包装代码。图 [11-8](#Fig8) 显示，对于尺寸为 320 x 240 的帧，如果我们使用包装代码抓取帧，检测器的运行速度会快 50 %!

![A978-1-4302-6080-6_11_Fig8_HTML.jpg](A978-1-4302-6080-6_11_Fig8_HTML.jpg)

图 11-8。

Color-based object detector using color frames from USB camera (top) and camera board (bottom)

### 基于 ORB 关键点的对象检测器

我们在[第 8 章](08.html)(清单 8-4)中开发的基于 ORB 关键点的对象检测器需要比计算直方图反投影多得多的计算量，因此当瓶颈不是帧抓取速度而是帧处理速度时，看看这两种方法如何执行是个好主意。图 [11-9](#Fig9) 显示使用包装器代码抓取 320 x 240 灰度帧(记住，ORB 关键点检测和描述只需要一张灰度图像)比从 USB 摄像头抓取彩色帧并手动将其转换为灰度图像快 14%。

![A978-1-4302-6080-6_11_Fig9_HTML.jpg](A978-1-4302-6080-6_11_Fig9_HTML.jpg)

图 11-9。

ORB-based object detector using frames grabbed from a USB camera (top) and camera board (bottom)

## 摘要

通过这一章，我结束了我们对嵌入式计算机视觉这一迷人领域的介绍。本章详细介绍了如何在无处不在的 Raspberry Pi 上运行自己的视觉算法，包括使用其时髦的新相机板。尽情发挥你的想象力，想出一些令人敬畏的用例！你会发现知道如何让一个 Raspberry Pi 理解它所看到的是一个非常强大的工具，它的应用是无限的。

除了 Pi 之外，市场上还有很多嵌入式系统可以运行 OpenCV。我的建议是选择一款最适合您的应用和预算的产品，并真正善于有效地使用它，而不是对所有嵌入式视觉产品都有所了解。归根结底，这些平台只是达到目的的一种手段；造成差异的是算法和思路。