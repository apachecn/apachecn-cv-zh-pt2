# 4.对图像和 GUI 窗口的基本操作

Abstract

在这一章中，你将最终开始接触你自己编写的 OpenCV 代码。我们将从一些简单的任务开始。本章将教你如何:

在这一章中，你将最终开始接触你自己编写的 OpenCV 代码。我们将从一些简单的任务开始。本章将教你如何:

*   在窗口中显示图像
*   将您的图像从彩色转换为灰度
*   创建 GUI 跟踪条并编写回调函数
*   从图像中裁剪部分
*   访问图像的单个像素
*   阅读、显示和编写视频

我们开始吧！从本章开始，我将假设您知道如何编译和运行您的代码，您熟悉目录/路径管理，并且您将把程序需要的所有文件(例如，输入图像)放在与可执行文件相同的目录中。

我还建议你在 [`http://docs.opencv.org/`](http://docs.opencv.org/) 广泛使用 OpenCV 文档。在本书中不可能讨论所有 OpenCV 函数的所有形式和用例。但是在文档页面上，关于所有 OpenCV 函数及其用法语法和参数类型的信息是以一种非常容易理解的方式组织起来的。所以每当你看到本书中介绍的新功能时，养成在文档中查找的习惯。您将熟悉使用该函数的各种方法，并且可能还会遇到几个相关的函数，这将增加您的技能。

## 在窗口中显示来自磁盘的图像

在 OpenCV 中显示磁盘映像非常简单。`highgui`模块的`imread()`、`namedWindow()`和`imshow()`功能为您完成所有工作。看一下清单 4-1，它在一个窗口中显示了一个图像，当你按 Esc 或‘Q’或‘Q’时退出(这和我们在[第二章](02.html)中用来检查 OpenCV 安装的代码完全一样):

清单 4-1。在窗口中显示图像

`#include <iostream>`

`#include <opencv2/highgui/highgui.hpp>`

`using namespace std;`

`using namespace cv;`

`int main(int argc, char **argv)`

`{`

`Mat im = imread("image.jpg", CV_LOAD_IMAGE_COLOR);`

`namedWindow("Hello");`

`imshow("Hello", im);`

`cout << "Press 'q' to quit..." << endl;`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

我现在将把代码分成几个部分来解释。

`Mat im = imread("image.jpg", CV_LOAD_IMAGE_COLOR);`

这创建了一个类型为`cv::Mat`的变量`im`(我们只写了`Mat`而不是`cv::Mat`，因为我们已经使用了上面的名称空间`cv;`，这是标准做法)。它还从磁盘中读取名为`image.jpg`的图像，并通过函数`imread(). CV_LOAD_IMAGE_COLOR`is flag(在`highgui.hpp`头文件中定义的常量)将其放入`im`中，该函数告诉`imread()`将图像作为彩色图像加载。彩色图像有三个通道——红色、绿色和蓝色，而灰度图像只有一个通道——强度。您可以使用标志`CV_LOAD_IMAGE_GRAYSCALE`将图像加载为灰度。这里的`im`类型为`CV_8UC3`，其中 8 表示每个通道中每个像素所占的位数，`U`表示无符号字符(每个像素的每个通道是一个 8 位无符号字符)，而`C3`表示 3 个通道。

`namedWindow("Hello");`

`imshow("Hello", im);`

首先创建一个名为 Hello 的窗口(Hello 也显示在窗口的标题栏中),然后在窗口中显示存储在`im`中的图像。就是这样！剩下的代码只是为了防止 OpenCV 在用户按下' Q '或' Q '之前退出并破坏窗口。

这里一个值得注意的函数是`waitKey()`。这将无限期等待一个按键事件(当`n <= 0`为正时)或等待`n`毫秒。它返回所按下的键的 ASCII 码，或者如果在指定时间过去之前没有按下键，则返回`-1`。注意`waitKey()`只有在 OpenCV GUI 窗口打开并处于焦点时才起作用。

## cv::Mat 结构

cv::Mat 结构是 OpenCV 中用于存储数据(图像等)的主要数据结构。稍微走点弯路，了解一下 cv::Mat 有多牛逼是值得的。

cv::Mat 被组织为一个标题和实际数据。因为数据的布局与其他库和 SDK 中使用的数据结构相似或兼容，所以这种组织允许非常好的互操作性。可以为用户分配的数据创建一个 cv::Mat 头，并使用 OpenCV 函数就地处理它。

表 [4-1](#Tab1) 、 [4-2](#Tab2) 、 [4-3](#Tab3) 描述了 cv::Mat 结构的一些常见操作。不要担心马上就能记住；相反，通读一遍，了解你能做的事情，然后使用这些表格作为参考。

### 创建 cv::Mat

表 4-1。

Creating a cv::Mat

<colgroup><col> <col></colgroup> 
| 句法 | 描述 |
| --- | --- |
| 双 m[2][2] = {{1.0，2.0}，{3.0，4.0 } }；mat m(2.2，CV_32F，m)； | 从多维数组数据创建一个 2 x 2 矩阵 |
| Mat M(100，100，CV_32FC2，标量(1，3))； | 创建一个 100 x 100 的双通道矩阵，第一个通道填充 1，第二个通道填充 3 |
| M.create(300，300，CV _ 8UC(15))； | 创建一个 300 x 300 的 15 通道矩阵，以前分配的数据将被释放 |
| int size[3]= { 7，8，9 }；Mat M(3，sizes，CV_8U，Scalar::all(0))； | 创建一个三维数组，其中每个维度的大小分别为 7、8 和 9。该数组用 0 填充 |
| mat m = mat::eye(7.7，cv _ 32f)； | 创建一个 7 x 7 的单位矩阵，每个元素是一个 32 位的浮点数 |
| Mat M = Mat::零(7.7，cv _ 64f)； | 创建一个用 64 位浮点零填充的 7 x 7 矩阵。类似地，Mat::ones()创建用 1 填充的矩阵 |

### 访问 cv::Mat 的元素

表 4-2。

Accessing elements from a cv::Mat

<colgroup><col> <col></colgroup> 
| 句法 | 描述 |
| --- | --- |
| M.at <double>(i，j)</double> | 访问 M 的第 I 行第 j 列的元素，M 是一个双精度矩阵。请注意，行号和列号从 0 开始 |
| M.row(1) | 访问 m 的第一行。注意行数从 0 开始 |
| 男 col(3) | 访问 m 的第 3 列。同样，列数从 0 开始 |
| m . rowrange(1.4) | 访问 M 的第 1 到第 4 行 |
| m . col range(1.4) | 访问 M 的第 1 到第 4 列 |
| m . rowrange(2.5)。colrange(1.3) | 访问 M 的第 2 至第 5 行和第 1 至第 3 列 |
| M.diag() | 访问方阵的对角线元素。也可用于从一组对角线值创建方阵 |

### 带 cv::Mat 的表达式

表 4-3。

Expressions with a cv::Mat

<colgroup><col> <col></colgroup> 
| 句法 | 描述 |
| --- | --- |
| 马特·M2 = m1 . clone()； | 让 M2 成为 M1 的翻版 |
| Mat M2(消歧义)：m1 . copy to(m2)； | 让 M2 成为 M1 的翻版 |
| Mat M1 = Mat::零(9.3，cv _ 32 fc 3)；mat m2 = m1 . reshape(0.3)； | 使 M2 成为具有与 M1 相同数量通道(由 0 表示)和 3 行(因此 9 列)的矩阵 |
| mat m2 = m1 . t()； | 使 M2 成为 M1 的翻版 |
| mat m2 = m1 . inv()； | 使 M2 成为 M1 的反面 |
| mat m3 = m1 * m2； | 使 M3 成为 M1 和 M2 的母体产物 |
| 马特·M2 = M1+s； | 将标量 s 添加到矩阵 M1，并将结果存储在 M2 中 |

关于 cv::Mats 的更多操作可以在 OpenCV 文档页面的 [`http://docs.opencv.org/modules/core/doc/basic_structures.html#mat`](http://docs.opencv.org/modules/core/doc/basic_structures.html#mat) 找到。

## 色彩空间之间的转换

色彩空间是描述图像中颜色的一种方式。最简单的颜色空间是 RGB 颜色空间，它只是将每个像素的颜色表示为红色、绿色和蓝色值，因为红色、绿色和蓝色是原色，您可以通过以各种比例组合这三种颜色来创建所有其他颜色。通常，每个“通道”是一个 8 位无符号整数(取值范围为 0-255)；因此，您会发现 OpenCV 中的大多数彩色图像都具有 CV_8UC3 类型。表 [4-4](#Tab4) 中描述了一些常见的 RGB 三元组。

表 4-4。

Common RGB triplets

<colgroup><col> <col></colgroup> 
| 三个一组 | 颜色 |
| --- | --- |
| (255, 0, 0) | 红色 |
| (0, 255, 0) | 格林（姓氏）；绿色的 |
| (0, 0, 255) | 蓝色 |
| (0, 0, 0) | 黑色 |
| (255, 255, 255) | 白色的 |

另一种颜色空间是灰度，从技术上讲根本不是颜色空间，因为它丢弃了颜色信息。它存储的只是每个像素的亮度，通常是一个 8 位无符号整数。还有许多其他颜色空间，其中值得注意的是 YUV、CMYK 和 LAB。(你可以在维基百科上读到它们。)

如前所述，通过 imread()分别使用 CV_LOAD_IMAGE_COLOR 和 CV _ LOAD _ IMAGE _ gray 标志，可以在 RGB 或灰度颜色空间中加载图像。然而，如果你已经加载了一个图像，OpenCV 有转换它的颜色空间的函数。出于各种原因，您可能希望在色彩空间之间进行转换。一个常见的原因是，YUV 颜色空间中的 U 和 V 通道编码所有颜色信息，但对照明或亮度不变。因此，如果你想对你的图像进行一些处理，需要光照不变，你应该转移到 YUV 颜色空间，并使用 U 和 V 通道(Y 通道专门存储强度信息)。注意，没有一个 R、G 或 B 通道是光照不变的。

函数 cvtColor()进行颜色空间转换。例如，要将 img1 中的 RGB 图像转换为灰度图像，您需要:

`cvtColor(img1, img2, CV_RGB2GRAY);`

其中 CV_RGB2GRAY 是一个预定义的代码，它告诉 OpenCV 要执行哪个转换。这个函数可以在许多颜色空间之间转换，你可以在 OpenCV 文档页面( [`http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=cvtcolor#cv.CvtColor`](http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=cvtcolor#cv.CvtColor) )上阅读更多关于它的内容。

## GUI 跟踪条和回调函数

本节将向您介绍 OpenCV `highgui`模块的一个非常有用的特性——跟踪条或滑块，以及操作它们所必需的回调函数。我们将使用滑块将图像从 RGB 颜色转换为灰度，反之亦然，因此希望这也将强化您的颜色空间转换概念。

### 回调函数

回调函数是事件发生时自动调用的函数。它们可以与 OpenCV 中的各种 GUI 事件相关联，比如单击鼠标左键或右键、移动滑块等等。对于我们的颜色空间转换应用程序，我们将把回调函数与滑块的移动关联起来。每当用户移动滑块时，这个函数就会被自动调用。简而言之，该函数检查滑块的值，并在相应地转换其颜色空间后显示图像。虽然这听起来很复杂，但是 OpenCV 让它变得非常简单。让我们看看清单 4-2 中的代码。

清单 4-2。色彩空间转换

`// Function to change between color and grayscale representations of an image using a GUI trackbar`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <iostream>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`// Global variables`

`const int slider_max = 1;`

`int slider;`

`Mat img;`

`// Callback function for trackbar event`

`void on_trackbar(int pos, void *)`

`{`

`Mat img_converted;`

`if(pos > 0) cvtColor(img, img_converted, CV_RGB2GRAY);`

`else img_converted = img;`

`imshow("Trackbar app", img_converted);`

`}`

`int main()`

`{`

`img = imread("image.jpg");`

`namedWindow("Trackbar app");`

`imshow("Trackbar app", img);`

`slider = 0;`

`createTrackbar("RGB <-> Grayscale", "Trackbar app", &slider, slider_max, on_trackbar);`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

像往常一样，我将把代码分成几个部分来解释。

台词

`const int slider_max = 1;`

`int slider;`

`Mat img;`

声明保存原始图像、滑块位置和最大可能滑块位置的全局变量。因为我们只需要滑块的两个选项——颜色和灰度(0 和 1 ),并且最小可能的滑块位置总是 0，所以我们将最大滑块位置设置为 1。全局变量是必要的，这样两个函数都可以访问它们。

台词

`img = imread("image.jpg");`

`namedWindow("Trackbar app");`

`imshow("Trackbar app", img);`

在主函数中，只需读取一个名为`image.jpg`的彩色图像，创建一个名为“Trackbar app”的窗口(创建跟踪条需要一个窗口)，并在窗口中显示图像。

`createTrackbar("RGB <-> Grayscale", "Trackbar app", &slider, slider_max, on_trackbar);`

在我们之前创建的名为“跟踪条应用”的窗口中创建一个名为“RGB 灰度”的跟踪条(你应该在 OpenCV 文档中查找这个函数)。我们还通过使用`&slider`、跟踪条的最大可能值以及将名为`on_trackbar`的回调函数与跟踪条事件相关联，传递一个指向保存跟踪条起始值的变量的指针。

现在让我们看看回调函数`on_trackbar(),`，它(对于跟踪条回调)必须总是类型`void foo(int. void *).`。这里的变量`pos`保存跟踪条的值，每次用户滑动跟踪条时，这个函数将被调用，并更新`pos`的值。台词

`if(pos > 0) cvtColor(img, img_converted, CV_RGB2GRAY);`

`else img_converted = img;`

`imshow("Trackbar app", img_converted);`

只需检查`pos`的值，并在之前创建的窗口中显示正确的图像。

编译并运行您的色彩空间转换器应用程序，如果一切顺利，您应该会看到它的运行，如图 [4-1](#Fig1) 所示。

![A978-1-4302-6080-6_4_Fig1a_HTML.jpg](A978-1-4302-6080-6_4_Fig1a_HTML.jpg) ![A978-1-4302-6080-6_4_Fig1b_HTML.jpg](A978-1-4302-6080-6_4_Fig1b_HTML.jpg)

图 4-1。

The color-space conversion app in action

## ROI:从图像中裁剪出一个矩形部分

在本节中，您将了解感兴趣区域。然后，您将使用这些知识制作一个应用程序，允许您选择图像中的矩形部分并将其裁剪掉。

### 图像中的感兴趣区域

感兴趣的区域正是它听起来的样子。这是我们特别感兴趣的图像区域，并且我们希望将我们的处理集中在这一区域上。它主要用于图像太大并且图像的所有部分都与我们的使用无关的情况；或者处理操作太重，以至于将其应用于整个图像在计算上是禁止的。通常 ROI 被指定为矩形。在 OpenCV 中，使用`rect`结构指定矩形 ROI(同样，在 OpenCV 文档中查找`rect`)。我们需要左上角的位置，宽度和高度来定义一个`rect`。

让我们看一下我们的应用程序的代码(清单 4-3 ),然后一次分析一点。

清单 4-3。从图像中裁剪出一部分

`// Program to crop images using GUI mouse callbacks`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <iostream>`

`#include <opencv2/highgui/highgui.hpp>`

`#include <opencv2/imgproc/imgproc.hpp>`

`using namespace std;`

`using namespace cv;`

`// Global variables`

`// Flags updated according to left mouse button activity`

`bool ldown = false, lup = false;`

`// Original image`

`Mat img;`

`// Starting and ending points of the user's selection`

`Point corner1, corner2;`

`// ROI`

`Rect box;`

`// Callback function for mouse events`

`static void mouse_callback(int event, int x, int y, int, void *)`

`{`

`// When the left mouse button is pressed, record its position and save it in corner1`

`if(event == EVENT_LBUTTONDOWN)`

`{`

`ldown = true;`

`corner1.x = x;`

`corner1.y = y;`

`cout << "Corner 1 recorded at " << corner1 << endl;`

`}`

`// When the left mouse button is released, record its position and save it in corner2`

`if(event == EVENT_LBUTTONUP)`

`{`

`// Also check if user selection is bigger than 20 pixels (jut for fun!)`

`if(abs(x - corner1.x) > 20 && abs(y - corner1.y) > 20)`

`{`

`lup = true;`

`corner2.x = x;`

`corner2.y = y;`

`cout << "Corner 2 recorded at " << corner2 << endl << endl;`

`}`

`else`

`{`

`cout << "Please select a bigger region" << endl;`

`ldown = false;`

`}`

`}`

`// Update the box showing the selected region as the user drags the mouse`

`if(ldown == true && lup == false)`

`{`

`Point pt;`

`pt.x = x;`

`pt.y = y;`

`Mat local_img = img.clone();`

`rectangle(local_img, corner1, pt, Scalar(0, 0, 255));`

`imshow("Cropping app", local_img);`

`}`

`// Define ROI and crop it out when both corners have been selected`

`if(ldown == true && lup == true)`

`{`

`box.width = abs(corner1.x - corner2.x);`

`box.height = abs(corner1.y - corner2.y);`

`box.x = min(corner1.x, corner2.x);`

`box.y = min(corner1.y, corner2.y);`

`// Make an image out of just the selected ROI and display it in a new window`

`Mat crop(img, box);`

`namedWindow("Crop");`

`imshow("Crop", crop);`

`ldown = false;`

`lup = false;`

`}`

`}`

`int main()`

`{`

`img = imread("image.jpg");`

`namedWindow("Cropping app");`

`imshow("Cropping app", img);`

`// Set the mouse event callback function`

`setMouseCallback("Cropping app", mouse_callback);`

`// Exit by pressing 'q'`

`while(char(waitKey(1)) != 'q') {}`

`return 0;`

`}`

这段代码目前看起来可能很大，但是，正如您可能已经意识到的，它的大部分只是鼠标事件的逻辑处理。在队列中

`setMouseCallback("Cropping app", mouse_callback);`

在主函数中，我们将鼠标回调设置为名为`mouse_callback`的函数。函数`mouse_callback`主要完成以下工作:

*   记录按下左键时鼠标的(x，y)位置。
*   记录释放左键时鼠标的(x，y)位置。
*   当这两项操作完成后，在图像中定义一个 ROI，并在另一个窗口中显示仅由 ROI 组成的另一个图像(您可以添加一个保存 ROI 的功能—为此使用 imwrite())。
*   绘制用户选择，并在用户拖动鼠标并按下左键时保持更新。

实现非常简单，一目了然。我想把重点放在这个程序中引入的三个新的编程特性上:`Point`、`rect`，以及通过指定一个`rect` ROI 从另一个图像创建一个图像。

`Point`结构用于存储关于一个点的信息，在我们的例子中是用户选择的角。该结构有两个数据成员，都是`int`，称为`x`和`y`。其他的点结构如`Point3d`、`Point2d`和`Point3f`也存在于 OpenCV 中，你应该在 OpenCV 文档中查看它们。

`rect`结构用于存储一个矩形的信息，使用它的`x`、`y`、`width`、`height. x`和`y`这里是图像中矩形左上角的坐标。

如果名为`r`的`rect`保存了图像`M1`中 ROI 的信息，您可以使用

`Mat M2(M1, r);`

裁剪应用程序看起来如图 [4-2](#Fig2) 所示。

![A978-1-4302-6080-6_4_Fig2_HTML.jpg](A978-1-4302-6080-6_4_Fig2_HTML.jpg)

图 4-2。

The cropping app in action

## 访问图像的单个像素

有时有必要访问图像或其 ROI 中各个像素的值。OpenCV 有有效的方法做到这一点。要访问`cv::Mat`图像中位置`(i, j)`处的像素，可以使用`cv::Mat`的`at()`属性，如下所示:

对于每个像素都是 8 位无符号字符的灰度图像`M`，使用`M.at<uchar>(i, j).`

对于 3 通道(RGB)图像`M`，其中每个像素是 3 个 8 位无符号字符的向量，使用`M.at<Vec3b>[c]`，其中`c`是通道号，从 0 到 2。

### 锻炼

能否根据目前所学的概念，制作一个非常简单的彩色图像分割 app？

分割意味着识别图像的不同部分。这里的零件是用颜色来定义的。我们希望识别图像中的红色区域:给定一个彩色图像，您应该产生一个黑白图像输出，其像素在原始图像的红色区域为 255(开)，在非红色区域为 0(关)。

您遍历彩色图像中的像素，检查它们的红色值是否在某个范围内。如果是，则打开输出图像的相应像素。你当然可以用简单的方法，遍历图像中的所有像素。但是看看你是否能在 OpenCV 文档中找到一个为你做完全相同任务的函数。也许你甚至可以做一个跟踪条来动态调整这个范围！

## 录像

OpenCV 中的视频通过 FFMPEG 支持进行处理。在继续本节中的代码之前，请确保您已经安装了支持 FFMPEG 的 OpenCV。

### 显示来自网络摄像头或 USB 摄像头/文件的源

让我们检查一段很短的代码(清单 4-4 ),它将显示来自你的计算机的默认摄像设备的视频。对于大多数笔记本电脑来说，这是集成的网络摄像头。

清单 4-4。显示来自默认摄像机设备的视频源

`// Program to display a video from attached default camera device`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <opencv2/opencv.hpp>`

`using namespace cv;`

`using namespace std;`

`int main()`

`{`

`// 0 is the ID of the built-in laptop camera, change if you want to use other camera`

`VideoCapture cap(0);`

`//check if the file was opened properly`

`if(!cap.isOpened())`

`{`

`cout << "Capture could not be opened successfully" << endl;`

`return -1;`

`}`

`namedWindow("Video");`

`// Play the video in a loop till it ends`

`while(char(waitKey(1)) != 'q' && cap.isOpened())`

`{`

`Mat frame;`

`cap >> frame;`

`// Check if the video is over`

`if(frame.empty())`

`{`

`cout << "Video over" << endl;`

`break;`

`}`

`imshow("Video", frame);`

`}`

`return 0;`

`}`

代码本身是不言自明的，我只想简单介绍几行代码。

`VideoCapture cap(0);`

这将创建一个 VideoCapture 对象，该对象链接到您计算机上的设备编号 0(默认设备)。和

`cap >> frame;`

从 VideoCapture 对象 cap 链接到的设备中提取帧。还有一些其他方法可以从相机设备中提取帧，特别是当您有多个相机并且想要同步它们时(同时从所有相机中提取帧)。我将在第十章中介绍这些方法。

您也可以给 VideoCapture 构造函数一个文件名，OpenCV 将以完全相同的方式为您播放该文件中的视频(参见清单 4-5)。

清单 4-5。显示文件中视频的程序

`// Program to display a video from a file`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`// Video from:`[`http://ftp.nluug.nl/ftp/graphics/blender/apricot/trailer/sintel_trailer-480p.mp4`T3】](http://ftp.nluug.nl/ftp/graphics/blender/apricot/trailer/sintel_trailer-480p.mp4)

`#include <opencv2/opencv.hpp>`

`using namespace cv;`

`using namespace std;`

`int main()`

`{`

`// Create a VideoCapture object to read from video file`

`VideoCapture cap("video.mp4");`

`//check if the file was opened properly`

`if(!cap.isOpened())`

`{`

`cout << "Capture could not be opened succesfully" << endl;`

`return -1;`

`}`

`namedWindow("Video");`

`// Play the video in a loop till it ends`

`while(char(waitKey(1)) != 'q' && cap.isOpened())`

`{`

`Mat frame;`

`cap >> frame;`

`// Check if the video is over`

`if(frame.empty())`

`{`

`cout << "Video over" << endl;`

`break;`

`}`

`imshow("Video", frame);`

`}`

`return 0;`

`}`

### 将视频写入磁盘

一个`VideoWriter`对象用于将视频写入磁盘。此类的构造函数需要以下内容作为输入:

*   输出文件名
*   输出文件的编解码器。在下面的代码中，我们使用 MPEG 编解码器，这是非常常见的。您可以使用`CV_FOURCC`宏指定编解码器。各种编解码器的四个字符代码可以在 [`www.fourcc.org/codecs.php`](http://www.fourcc.org/codecs.php) 找到。请注意，要使用编解码器，您必须在计算机上安装该编解码器
*   帧频
*   框架尺寸

你可以得到一个视频的各种属性(像帧大小，帧速率，亮度，对比度，曝光度等。)从一个`VideoCapture`对象使用`get()`函数。在清单 4-6 中，它将视频从默认的摄像机设备写入磁盘，我们使用`get()`函数来获取帧的大小。如果你的相机支持的话，你也可以用它来获得帧速率。

清单 4-6。将视频从默认摄像机设备源写入磁盘的代码

`// Program to write video from default camera device to file`

`// Author: Samarth Manoj Brahmbhatt, University of Pennsylvania`

`#include <opencv2/opencv.hpp>`

`using namespace cv;`

`using namespace std;`

`int main()`

`{`

`// 0 is the ID of the built-in laptop camera, change if you want to use other camera`

`VideoCapture cap(0);`

`//check if the file was opened properly`

`if(!cap.isOpened())`

`{`

`cout << "Capture could not be opened succesfully" << endl;`

`return -1;`

`}`

`// Get size of frames`

`Size S = Size((int) cap.get(CV_CAP_PROP_FRAME_WIDTH), (int) cap.get(CV_CAP_PROP_FRAME_HEIGHT));`

`// Make a video writer object and initialize it at 30 FPS`

`VideoWriter put("output.mpg", CV_FOURCC('M','P','E','G'), 30, S);`

`if(!put.isOpened())`

`{`

`cout << "File could not be created for writing. Check permissions" << endl;`

`return -1;`

`}`

`namedWindow("Video");`

`// Play the video in a loop till it ends`

`while(char(waitKey(1)) != 'q' && cap.isOpened())`

`{`

`Mat frame;`

`cap >> frame;`

`// Check if the video is over`

`if(frame.empty())`

`{`

`cout << "Video over" << endl;`

`break;`

`}`

`imshow("Video", frame);`

`put << frame;`

`}`

`return 0;`

`}`

## 摘要

在这一章中，您接触了大量的 OpenCV 代码，并且看到了编写复杂任务的程序是多么容易，比如在 OpenCV 中显示视频。这一章没有很多计算机视觉。它的目的是向您介绍 OpenCV 的来龙去脉。下一章将处理图像过滤和转换，并将利用你在这里学到的编程概念。